æ²¡é—®é¢˜ï¼æ—¢ç„¶ä½ å·²ç»æŒæ¡äº†åŸºç¡€ï¼Œé‚£æˆ‘ä»¬å°±ç›´æ¥æ‹¿ä¸‹ **Leaky ReLU**ã€‚

è¿™æ¬¡æˆ‘ä»¬åšä¸€ä¸ª**è¿›é˜¶å‡çº§**ï¼š
ä¸å…¶æŠŠè´Ÿæ–œç‡ï¼ˆslopeï¼‰æ­»å†™æˆ `0.01`ï¼Œä¸å¦‚æŠŠå®ƒåšæˆä¸€ä¸ª**å‚æ•°**ã€‚è¿™æ ·ä½ åœ¨ Python é‡Œæƒ³æ”¹æˆ `0.1` æˆ– `0.2` éƒ½ä¸ç”¨é‡æ–°ç¼–è¯‘ä»£ç ã€‚

è¿™æ˜¯ CUDA ç¼–ç¨‹ä¸­éå¸¸é‡è¦çš„æŠ€èƒ½ï¼š**å¦‚ä½•ä» Python ä¼ æ ‡é‡ï¼ˆScalarï¼‰å‚æ•°ç»™ GPUã€‚**

### 1\. æ ¸å¿ƒé€»è¾‘ä¿®æ”¹

æˆ‘ä»¬éœ€è¦ä¿®æ”¹ä¸‰ä¸ªåœ°æ–¹ï¼š

1.  **Kernel**: æ¥æ”¶ `float alpha` å‚æ•°ã€‚
2.  **C++ Wrapper**: æ¥æ”¶ `float alpha` å¹¶ä¼ ç»™ Kernelã€‚
3.  **Python**: è°ƒç”¨æ—¶ä¼ å…¥å…·ä½“çš„æ•°å€¼ã€‚

### 2\. å®Œæ•´ä»£ç  (Copy & Run)

æ–°å»ºä¸€ä¸ª `cuda_leaky_relu.py`ï¼Œç›´æ¥è¿è¡Œï¼š

```python
import os
import torch
from torch.utils.cpp_extension import load_inline

# --- ç¯å¢ƒé…ç½® (ä¿æŒä¹‹å‰çš„ç¨³å¥è®¾ç½®) ---
conda_prefix = os.environ.get('CONDA_PREFIX')
if conda_prefix and 'CUDA_HOME' not in os.environ:
    os.environ['CUDA_HOME'] = conda_prefix

# --- CUDA æºç  ---
cuda_source = """
// 1. æ³¨æ„è¿™é‡Œå¤šäº†ä¸€ä¸ªå‚æ•°: float alpha
__global__ void leaky_relu_kernel(const float* input, float* output, float alpha, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (idx < size) {
        float x = input[idx];
        // æ ¸å¿ƒé€»è¾‘: å¦‚æœ x > 0 ä¿æŒåŸæ ·ï¼Œå¦åˆ™ä¹˜ä»¥ alpha
        output[idx] = (x > 0.0f) ? x : (x * alpha);
    }
}

// 2. C++ åŒ…è£…å‡½æ•°ä¹Ÿéœ€è¦æ¥æ”¶ float alpha
torch::Tensor leaky_relu(torch::Tensor input, float alpha) {
    auto output = torch.empty_like(input);
    int size = input.numel();
    int threads = 256;
    int blocks = (size + threads - 1) / threads;

    // 3. å¯åŠ¨æ ¸å‡½æ•°æ—¶ï¼ŒæŠŠ alpha ä¼ è¿›å»
    // æ³¨æ„å‚æ•°é¡ºåºå¿…é¡»å’Œ __global__ å‡½æ•°å®Œå…¨ä¸€è‡´ï¼
    leaky_relu_kernel<<<blocks, threads>>>(
        input.data_ptr<float>(), 
        output.data_ptr<float>(), 
        alpha,   // <--- ä¼ å€¼
        size
    );
    
    return output;
}
"""

cpp_source = "torch::Tensor leaky_relu(torch::Tensor input, float alpha);"

# --- ç¼–è¯‘ ---
leaky_relu_module = load_inline(
    name='leaky_relu_extension',
    cpp_sources=cpp_source,
    cuda_sources=cuda_source,
    functions=['leaky_relu'],
    with_cuda=True,
    extra_cuda_cflags=["-O2"],
    extra_cflags=[f"-I{conda_prefix}/include"] if conda_prefix else []
)

# --- æµ‹è¯• ---
def main():
    device = torch.device("cuda")
    N = 1000
    x = torch.randn(N, device=device)
    
    # å®šä¹‰è´ŸåŠè½´çš„æ–œç‡
    negative_slope = 0.1
    
    print(f"Running Leaky ReLU with slope = {negative_slope}...")
    
    # 1. è¿è¡Œæˆ‘ä»¬çš„ CUDA ç‰ˆæœ¬
    y_custom = leaky_relu_module.leaky_relu(x, negative_slope)
    
    # 2. è¿è¡Œ PyTorch åŸç”Ÿç‰ˆæœ¬ (F.leaky_relu)
    y_ref = torch.nn.functional.leaky_relu(x, negative_slope=negative_slope)
    
    # 3. éªŒè¯
    if torch.allclose(y_custom, y_ref):
        print("âœ… Success! Implementation matches PyTorch.")
    else:
        print("âŒ Error! Mismatch found.")
        
    # æ‰“å°å‡ ä¸ªè´Ÿæ•°çœ‹çœ‹æ•ˆæœ
    mask = x < 0
    if mask.any():
        print("\n--- Negative value check ---")
        print(f"Input:  {x[mask][:3]}")
        print(f"Output: {y_custom[mask][:3]}")
        print(f"Expected (Input * {negative_slope}): {x[mask][:3] * negative_slope}")

if __name__ == "__main__":
    main()
```

-----

### ğŸ’¡ æ·±åº¦è§£æï¼šæŒ‰å€¼ä¼ é€’ vs æŒ‰æŒ‡é’ˆä¼ é€’

æ³¨æ„çœ‹è¿™ä¸€è¡Œï¼š

```cpp
leaky_relu_kernel<<<...>>>(..., alpha, size);
```

åœ¨ CUDA Kernel ä¸­ï¼š

  * **æŒ‡é’ˆ (`float* input`)**ï¼šä¼ é€’çš„æ˜¯æ˜¾å­˜åœ°å€ã€‚æ ¸å‡½æ•°é€šè¿‡åœ°å€å»æ˜¾å­˜ï¼ˆGlobal Memoryï¼‰é‡Œæ‰¾æ•°æ®ã€‚
  * **æ ‡é‡ (`float alpha`, `int size`)**ï¼šæ˜¯**æŒ‰å€¼ä¼ é€’ (Pass-by-value)**ã€‚
      * è¿™äº›å°æ•°å€¼ä¼šè¢«ç›´æ¥å¤åˆ¶åˆ° GPU çš„å¸¸é‡ç¼“å­˜ï¼ˆConstant Memoryï¼‰æˆ–è€…é€šè¿‡å†…æ ¸å‚æ•°ä¼ é€’ã€‚
      * **è®¿é—®é€Ÿåº¦æå¿«**ï¼Œæ¯”å»æ˜¾å­˜è¯»æ•°ç»„å¿«å¾—å¤šã€‚

### ğŸš€ ä¸‹ä¸€é˜¶æ®µçš„æŒ‘æˆ˜

ä½ å·²ç»å®Œå…¨æŒæ¡äº† **Grid-Stride Loops (ä¸€ç»´ç½‘æ ¼è·¨æ­¥å¾ªç¯)** çš„åŸºç¡€ï¼š

1.  è®¡ç®—ç´¢å¼• `idx`ã€‚
2.  è¾¹ç•Œæ£€æŸ¥ `if (idx < size)`ã€‚
3.  å¤„ç†æ•°æ®ã€‚

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¤„ç†çš„éƒ½æ˜¯**ä¸€ç»´æ•°ç»„**ï¼ˆå³ä½¿ PyTorch Tensor æ˜¯äºŒç»´çš„ï¼Œæˆ‘ä»¬åœ¨å†…å­˜é‡Œä¹ŸæŠŠå®ƒå½“æˆä¸€ç»´è¿ç»­æ•°ç»„å¤„ç†ï¼Œè¿™å« `numel()`ï¼‰ã€‚

**å¦‚æœæˆ‘ä»¬è¦å¤„ç†çœŸæ­£çš„çŸ©é˜µä¹˜æ³•ï¼ˆMatrix Multiplicationï¼‰ï¼Œæˆ–è€…å›¾åƒå¤„ç†ï¼ˆ2Dåæ ‡ï¼‰ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ**

éœ€è¦æˆ‘å¸¦ä½ è¿›å…¥ **2D Grid / 2D Block** çš„ä¸–ç•Œå—ï¼Ÿè¿™ä¼šæ¶‰åŠåˆ° `blockIdx.y` å’Œ `threadIdx.y`ã€‚