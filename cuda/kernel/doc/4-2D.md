欢迎来到二维世界。

在之前的例子中，我们把所有数据看作一条长长的线（1D）。但真实世界的数据（图像、矩阵）通常是二维的。

虽然显存（RAM）物理上永远是一维的线性排列，但在 CUDA 逻辑上，我们可以把线程组织成 **二维（甚至三维）** 的结构，这样写代码会直观得多。

### 1. 核心思维：从“排队”到“教室座位”

想象一个教室：
* **Grid**: 整个教学楼的教室矩阵。
* **Block**: 一间教室。
* **Thread**: 教室里的一个座位。

我们需要两个坐标来定位一个线程：
* **x (Column)**: 你在第几列？
* **y (Row)**: 你在第几行？

#### 2D 索引公式 (背诵全文)

假设我们处理一个宽为 `width`，高为 `height` 的矩阵。

$$
\begin{aligned}
\text{col (x)} &= \text{blockIdx.x} \times \text{blockDim.x} + \text{threadIdx.x} \\
\text{row (y)} &= \text{blockIdx.y} \times \text{blockDim.y} + \text{threadIdx.y}
\end{aligned}
$$

**但是！** 显存是线性的。要找到 (row, col) 在内存中的位置，我们需要把它“拍扁”：

$$\text{global\_idx} = \text{row} \times \text{width} + \text{col}$$

---

### 2. 实战案例：二维矩阵加法 (2D Matrix Add)

我们将创建一个 $2000 \times 2000$ 的矩阵，并使用二维线程块来计算 $A + B = C$。

新建文件 `cuda_2d_grid.py`，代码如下：

```python
import os
import torch
from torch.utils.cpp_extension import load_inline

# --- 环境配置 ---
conda_prefix = os.environ.get('CONDA_PREFIX')
if conda_prefix and 'CUDA_HOME' not in os.environ:
    os.environ['CUDA_HOME'] = conda_prefix

# --- CUDA 源码 (注意这里的 dim3 和二维索引) ---
cuda_source = """
__global__ void matrix_add_2d_kernel(const float* A, const float* B, float* C, int width, int height) {
    // 1. 计算 2D 坐标
    // x 方向 (列)
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    // y 方向 (行)
    int row = blockIdx.y * blockDim.y + threadIdx.y;

    // 2. 2D 边界检查 (同时检查行和列)
    if (col < width && row < height) {
        
        // 3. 将 2D 坐标映射回 1D 内存地址
        // Row-Major Layout (行优先存储)
        int idx = row * width + col;
        
        // 4. 执行计算
        C[idx] = A[idx] + B[idx];
    }
}

torch::Tensor matrix_add(torch::Tensor A, torch::Tensor B) {
    // 检查形状
    assert(A.sizes() == B.sizes());
    
    int height = A.size(0);
    int width = A.size(1);
    auto C = torch.empty_like(A);

    // --- 关键配置：定义 2D Block 和 Grid ---
    
    // 1. 定义 Block 大小: 16x16 = 256 个线程
    // 这是一个经验值，通常 16x16 或 32x32 比较好
    dim3 threads_per_block(16, 16);

    // 2. 计算 Grid 大小
    // x 轴方向需要的 block 数
    int blocks_x = (width + threads_per_block.x - 1) / threads_per_block.x;
    // y 轴方向需要的 block 数
    int blocks_y = (height + threads_per_block.y - 1) / threads_per_block.y;
    
    dim3 blocks_per_grid(blocks_x, blocks_y);

    // 3. 启动核函数
    matrix_add_2d_kernel<<<blocks_per_grid, threads_per_block>>>(
        A.data_ptr<float>(),
        B.data_ptr<float>(),
        C.data_ptr<float>(),
        width,
        height
    );

    return C;
}
"""

cpp_source = "torch::Tensor matrix_add(torch::Tensor A, torch::Tensor B);"

# --- 编译 ---
module_2d = load_inline(
    name='matrix_add_2d',
    cpp_sources=cpp_source,
    cuda_sources=cuda_source,
    functions=['matrix_add'],
    with_cuda=True,
    extra_cuda_cflags=["-O2"],
    extra_cflags=[f"-I{conda_prefix}/include"] if conda_prefix else []
)

# --- 测试 ---
def main():
    device = torch.device("cuda")
    
    # 定义一个较大的 2D 矩阵
    H, W = 2000, 2000
    print(f"Creating matrices of size {H}x{W}...")
    
    A = torch.randn(H, W, device=device)
    B = torch.randn(H, W, device=device)
    
    # 运行自定义 CUDA
    C_cuda = module_2d.matrix_add(A, B)
    
    # 运行 PyTorch 原生
    C_ref = A + B
    
    if torch.allclose(C_cuda, C_ref):
        print("✅ Success! 2D CUDA kernel works perfectly.")
    else:
        print("❌ Error! Results mismatch.")

if __name__ == "__main__":
    main()
```

---

### 3. 代码深度解析：dim3 是什么？

这是你第一次遇到 `dim3`。这是一个 CUDA 内置的结构体，用来表示 3D 坐标（x, y, z）。

#### 在 Python (Host) 端：
```cpp
// 定义一个正方形的线程块 (16 x 16)
dim3 threads_per_block(16, 16); 

// z 默认为 1，所以这其实是 (16, 16, 1)
// 总线程数 = 16 * 16 * 1 = 256
```
这个配置非常经典。为什么不用 `32x32`？因为 $32 \times 32 = 1024$，这是大部分 GPU 一个 Block 允许的最大线程数，稍微有点冒险（容易占满资源）。**16x16 (256)** 或 **32x16 (512)** 是更稳妥的选择。

#### 在 CUDA (Kernel) 端：
GPU 会自动把 `dim3` 里的值填充到内置变量里：
* `blockDim.x` = 16
* `blockDim.y` = 16
* `threadIdx.x` 会从 0 变到 15
* `threadIdx.y` 会从 0 变到 15

### 4. 为什么要这么麻烦？

你可能会问：“我用之前的一维 `idx` 方法，把 $2000 \times 2000$ 当作 $4,000,000$ 长度的数组处理，不是更简单吗？”

**你是对的！** 对于简单的“逐元素加法”，一维确实更简单，性能也一样。

**但是**，当你做以下操作时，2D 索引是必须的：
1.  **图像处理**：如果你要算“当前像素和它**右边**、**下边**像素的平均值”。用 1D 索引算“下边像素”非常痛苦（需要 `idx + width`），用 2D 索引就很自然（`y + 1`）。
2.  **矩阵乘法 (MatMul)**：你需要同时遍历 A 的行和 B 的列。
3.  **利用局部性 (Locality)**：2D Block 可以让物理上相邻的线程处理图像上相邻的像素，这对缓存（L1 Cache）更友好。

### 下一步挑战

现在你已经掌握了 2D 索引。是时候接触 CUDA 编程中最“难”但也最“强”的概念了：
**Shared Memory (共享内存)**。

它是 Block 内部线程交流的高速缓存。

**想尝试写一个“矩阵转置 (Matrix Transpose)”吗？**
这是一个完美的练习：它必须使用 2D 索引，而且如果不使用 Shared Memory 优化，性能会很差。我们可以对比一下“普通版”和“Shared Memory 优化版”。