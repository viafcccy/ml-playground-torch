# GPU 完整学习路线图

## 1. 硬件架构基础

### 1.1 GPU 核心架构
- **流式多处理器 (SM/CU)**
  - NVIDIA 的 Streaming Multiprocessor (SM)
  - AMD 的 Compute Unit (CU)
  - SM/CU 的内部结构与调度机制
- **计算核心**
  - CUDA Core / Stream Processor（标准浮点运算）
  - Tensor Core / Matrix Core（矩阵运算加速）
  - RT Core（光线追踪专用核心）
  - FP32/FP16/INT8/BF16 精度支持
- **寄存器与缓存**
  - 寄存器文件（Register File）
  - 共享内存（Shared Memory / LDS）
  - L1 Cache
  - L2 Cache
  - 只读缓存（Constant Cache、Texture Cache）

### 1.2 内存系统
- **显存 (VRAM)**
  - GDDR6 / GDDR6X
  - HBM2 / HBM2e / HBM3
  - 显存容量与带宽
- **内存访问**
  - 内存控制器
  - 内存总线位宽
  - 内存延迟与带宽
  - ECC 内存保护
- **互联技术**
  - PCIe 3.0/4.0/5.0
  - NVLink（NVIDIA）
  - Infinity Fabric（AMD）
  - CXL（Compute Express Link）

### 1.3 GPU 架构演进
- **NVIDIA 架构**
  - Pascal (2016) - GTX 10 系列
  - Volta (2017) - 首次引入 Tensor Core
  - Turing (2018) - RT Core 光追
  - Ampere (2020) - RTX 30 系列
  - Ada Lovelace (2022) - RTX 40 系列
  - Hopper (2022) - H100 数据中心
  - Blackwell (2024) - B100/B200
- **AMD 架构**
  - GCN (Graphics Core Next)
  - RDNA 1/2/3 - 游戏显卡
  - CDNA 1/2/3 - 数据中心 (MI 系列)
- **Intel 架构**
  - Xe-HPG (Arc 游戏显卡)
  - Xe-HPC (Ponte Vecchio)
  - Xe-LP/LPG (集成显卡)

### 1.4 性能指标
- **计算性能**
  - TFLOPS（万亿次浮点运算/秒）
  - INT8/FP16/FP32/FP64 性能
- **内存性能**
  - 内存带宽（GB/s）
  - 内存容量
- **功耗与效率**
  - TDP（热设计功耗）
  - 性能功耗比
- **制程工艺**
  - 7nm / 5nm / 4nm
  - 晶体管数量
  - 芯片面积

---

## 2. 并行编程基础

### 2.1 CUDA 编程模型
- **基础概念**
  - Host（CPU）vs Device（GPU）
  - Kernel 函数
  - 线程层次结构
    - Thread（线程）
    - Block（线程块）
    - Grid（网格）
  - 线程索引计算：threadIdx, blockIdx, blockDim, gridDim
- **内存模型**
  - 全局内存（Global Memory）
  - 共享内存（Shared Memory）
  - 寄存器（Register）
  - 本地内存（Local Memory）
  - 常量内存（Constant Memory）
  - 纹理内存（Texture Memory）
- **执行模型**
  - Warp（线程束，32个线程）
  - Warp 调度与执行
  - SIMT（Single Instruction, Multiple Thread）
  - 分支发散（Branch Divergence）
- **同步机制**
  - `__syncthreads()` - 块内同步
  - Atomic 操作
  - Memory Fence
  - Cooperative Groups

### 2.2 其他编程框架
- **OpenCL**
  - 跨平台异构计算
  - Work-item, Work-group, NDRange
  - Kernel 语言
- **HIP (AMD)**
  - CUDA 到 AMD 的移植
  - ROCm 平台
- **SYCL**
  - 基于 C++ 的异构编程
  - Intel oneAPI
- **Vulkan Compute**
  - 现代图形 API 的计算着色器
- **DirectCompute**
  - Windows 平台的计算着色器

### 2.3 并行算法设计
- **基本并行模式**
  - Map（映射）
  - Reduce（归约）
  - Scan（前缀和）
  - Scatter/Gather
  - Stencil（模板计算）
- **数据分解策略**
  - 一维/二维/三维分解
  - 块分解
  - 循环分解
- **负载均衡**
  - 静态负载均衡
  - 动态负载均衡
  - Work stealing

---

## 3. CUDA 高级编程

### 3.1 内存优化
- **内存访问模式**
  - 合并访问（Coalesced Access）
  - Bank Conflict（共享内存银行冲突）
  - 对齐访问
  - 跨步访问（Strided Access）
- **共享内存使用**
  - Tiling 技术
  - 数据重用
  - 双缓冲
- **纹理内存**
  - 2D/3D 纹理
  - 插值与过滤
  - Surface 内存
- **统一内存 (Unified Memory)**
  - 自动数据迁移
  - 页面迁移
  - 访问计数器

### 3.2 流与并发
- **CUDA Stream**
  - 异步执行
  - 流的创建与销毁
  - 流的同步
  - 默认流与非默认流
- **并发内核执行**
  - 多流并发
  - 内核与数据传输重叠
  - 事件（Event）
- **动态并行**
  - 内核中启动内核
  - 父子网格

### 3.3 多 GPU 编程
- **多 GPU 策略**
  - 数据并行
  - 模型并行
  - 流水线并行
- **GPU 间通信**
  - P2P（Peer-to-Peer）访问
  - NVLink
  - GPUDirect RDMA
  - NCCL（NVIDIA Collective Communications Library）
- **MPI + CUDA**
  - 混合编程模型
  - 通信与计算重叠

### 3.4 性能分析与调试
- **性能分析工具**
  - NVIDIA Nsight Compute
  - NVIDIA Nsight Systems
  - AMD ROCProfiler
  - nvprof / nvvp（已废弃）
- **调试工具**
  - cuda-gdb
  - CUDA-MEMCHECK
  - Compute Sanitizer
- **性能指标**
  - 占用率（Occupancy）
  - IPC（Instructions Per Cycle）
  - 内存带宽利用率
  - Warp 执行效率

### 3.5 编译与底层
- **编译流程**
  - nvcc 编译器
  - 编译选项优化
  - 分离编译
- **汇编语言**
  - PTX（Parallel Thread Execution）
  - SASS（SM Assembly）
  - cubin 二进制
- **JIT 编译**
  - 运行时编译
  - 缓存管理

---

## 4. 深度学习与 AI

### 4.1 深度学习框架
- **训练框架**
  - **PyTorch**
    - torch.cuda 模块
    - Autograd 自动微分
    - 分布式训练（DDP, FSDP）
    - torch.compile
  - **TensorFlow**
    - XLA 编译器
    - tf.distribute 策略
  - **JAX**
    - JIT 编译
    - 自动向量化
  - **PaddlePaddle / MindSpore**
- **分布式训练**
  - 数据并行（Data Parallel）
  - 模型并行（Model Parallel）
  - 流水线并行（Pipeline Parallel）
  - 张量并行（Tensor Parallel）
  - ZeRO 优化器

### 4.2 推理优化
- **推理引擎**
  - TensorRT（NVIDIA）
  - ONNX Runtime
  - OpenVINO（Intel）
  - TVM / Apache TVM
  - MNN / NCNN（移动端）
- **模型优化技术**
  - 量化（INT8/INT4/FP16）
  - 剪枝（Pruning）
  - 蒸馏（Distillation）
  - 算子融合（Operator Fusion）
  - 动态 Batching
- **服务部署**
  - Triton Inference Server
  - TorchServe
  - TensorFlow Serving

### 4.3 GPU 加速库
- **线性代数**
  - cuBLAS（矩阵运算）
  - cuSPARSE（稀疏矩阵）
  - cuSOLVER（求解器）
- **深度学习原语**
  - cuDNN（卷积、池化等）
  - CUTLASS（Tensor Core 编程）
  - Flash Attention
  - Triton（OpenAI 的 DSL）
- **其他数学库**
  - cuFFT（快速傅里叶变换）
  - cuRAND（随机数生成）
  - Thrust（并行算法库）

### 4.4 大模型训练
- **Transformer 优化**
  - Multi-head Attention 加速
  - Flash Attention / Flash Attention 2
  - PagedAttention（vLLM）
- **混合精度训练**
  - FP16/BF16 混合精度
  - Loss Scaling
  - Automatic Mixed Precision (AMP)
- **内存优化**
  - Gradient Checkpointing
  - Activation Checkpointing
  - CPU Offloading
  - ZeRO-Offload
- **大规模训练框架**
  - Megatron-LM
  - DeepSpeed
  - Colossal-AI

---

## 5. 图形渲染

### 5.1 图形管线
- **渲染管线阶段**
  - 应用阶段
  - 几何阶段
    - 顶点着色器（Vertex Shader）
    - 曲面细分着色器（Tessellation）
    - 几何着色器（Geometry Shader）
  - 光栅化（Rasterization）
  - 片段阶段
    - 片段着色器（Fragment/Pixel Shader）
  - 输出合并
- **可编程着色器**
  - Compute Shader（计算着色器）
  - 着色器语言（GLSL, HLSL, SPIR-V）

### 5.2 图形 API
- **现代图形 API**
  - Vulkan（跨平台）
  - DirectX 12（Windows）
  - Metal（Apple）
- **传统图形 API**
  - OpenGL
  - DirectX 11
- **WebGPU**
  - 浏览器图形 API

### 5.3 实时渲染技术
- **基础渲染**
  - 前向渲染
  - 延迟渲染（Deferred Rendering）
  - 前向+延迟混合
- **光照技术**
  - Phong/Blinn-Phong
  - PBR（基于物理的渲染）
  - IBL（基于图像的光照）
- **全局光照**
  - 屏幕空间反射（SSR）
  - 屏幕空间环境光遮蔽（SSAO）
  - 体积光照
- **阴影技术**
  - Shadow Mapping
  - Cascaded Shadow Maps
  - Ray Traced Shadows

### 5.4 光线追踪
- **实时光线追踪**
  - DXR（DirectX Raytracing）
  - Vulkan Ray Tracing
  - OptiX（NVIDIA）
- **加速结构**
  - BVH（Bounding Volume Hierarchy）
  - 硬件加速（RT Core）
- **降噪技术**
  - 时域降噪
  - 空域降噪
  - AI 降噪

### 5.5 超分辨率与帧生成
- **DLSS（Deep Learning Super Sampling）**
  - DLSS 2/3
  - Frame Generation
- **FSR（FidelityFX Super Resolution）**
  - FSR 1/2/3
- **XeSS（Intel）**
- **TAA（Temporal Anti-Aliasing）**

---

## 6. 通用计算 (GPGPU)

### 6.1 科学计算
- **计算流体力学 (CFD)**
  - Navier-Stokes 方程求解
  - 湍流模拟
- **分子动力学**
  - GROMACS
  - LAMMPS
  - NAMD
- **量子化学**
  - 密度泛函理论（DFT）
  - 分子轨道计算
- **气候与天气模拟**
- **天体物理学**
  - N-body 模拟
  - 宇宙学模拟

### 6.2 图像与视频处理
- **计算机视觉**
  - OpenCV GPU 模块
  - 图像滤波
  - 特征提取
  - 目标检测
- **视频编解码**
  - NVENC/NVDEC（NVIDIA）
  - VCE/VCN（AMD）
  - H.264/H.265/AV1
- **图像处理算法**
  - 卷积滤波
  - 形态学操作
  - 频域变换

### 6.3 数据分析
- **RAPIDS 生态**
  - cuDF（GPU DataFrame）
  - cuML（机器学习）
  - cuGraph（图计算）
  - cuSpatial（地理空间）
- **数据库加速**
  - GPU 加速数据库
  - SQL 查询加速
- **大数据处理**
  - Spark + GPU
  - 数据预处理

### 6.4 金融计算
- **蒙特卡洛模拟**
  - 期权定价
  - 风险评估
- **高频交易**
  - 实时分析
- **投资组合优化**

### 6.5 其他应用
- **密码学**
  - 哈希计算
  - 加密解密
- **区块链与挖矿**
  - PoW 算法
- **生物信息学**
  - 基因测序
  - 蛋白质折叠

---

## 7. 性能优化技术

### 7.1 算法层优化
- **减少分支**
  - 避免 warp 内分支发散
  - 使用位运算替代条件判断
- **提高数据局部性**
  - 时间局部性
  - 空间局部性
  - Cache-friendly 数据结构
- **算法选择**
  - 并行友好的算法
  - 减少同步开销

### 7.2 内存层优化
- **合并访问**
  - 连续内存访问
  - 对齐访问
- **共享内存优化**
  - 避免 Bank Conflict
  - Padding 技术
  - 双缓冲
- **减少全局内存访问**
  - 数据重用
  - 共享内存缓存
- **使用特殊内存**
  - 只读数据用常量内存
  - 纹理内存的空间局部性
- **内存传输优化**
  - 异步传输
  - Pinned Memory
  - 零拷贝内存

### 7.3 指令层优化
- **循环展开**
  - `#pragma unroll`
  - 减少循环控制开销
- **指令级并行**
  - ILP（Instruction Level Parallelism）
  - 独立指令
- **使用内建函数**
  - `__fdividef()` 快速除法
  - `__expf()` 快速指数
  - `__sinf()`, `__cosf()` 快速三角函数
- **Warp 级原语**
  - Warp Shuffle
  - Warp Reduce
  - Warp Vote

### 7.4 并行策略优化
- **网格步长循环**
  - Grid-stride loop
  - 适应任意问题规模
- **动态调度**
  - 任务队列
  - Work stealing
- **负载均衡**
  - 数据分区
  - 动态粒度调整
- **多流并发**
  - 内核并发执行
  - 计算与传输重叠

### 7.5 配置参数调优
- **Block 大小选择**
  - 通常是 32 的倍数（warp 大小）
  - 常用：128, 256, 512
  - 占用率计算器
- **寄存器使用**
  - 控制寄存器数量
  - 避免寄存器溢出
- **占用率优化**
  - 平衡寄存器和共享内存使用
  - Active warps 最大化

---

## 8. 新兴技术与前沿

### 8.1 AI 前沿
- **大语言模型 (LLM)**
  - GPT/BERT/LLaMA 训练
  - Inference 优化
  - KV Cache 优化
- **多模态模型**
  - CLIP/DALL-E
  - Stable Diffusion
  - 视觉-语言模型
- **强化学习**
  - GPU 加速环境模拟
  - 策略训练
- **稀疏计算**
  - MoE（Mixture of Experts）
  - 结构化稀疏
  - N:M 稀疏

### 8.2 边缘计算
- **嵌入式 GPU**
  - NVIDIA Jetson 系列
    - Jetson Nano
    - Jetson AGX Orin
  - 移动 GPU (Qualcomm Adreno, ARM Mali)
- **功耗优化**
  - 动态电压频率调整（DVFS）
  - 低功耗模式
- **模型压缩**
  - 轻量化网络
  - 知识蒸馏

### 8.3 自动驾驶
- **感知**
  - 目标检测
  - 语义分割
  - 3D 点云处理
- **决策规划**
  - 路径规划
  - 行为预测
- **端到端模型**
  - 传感器融合
  - 实时推理

### 8.4 其他前沿
- **量子模拟**
  - GPU 加速量子电路模拟
- **神经形态计算**
  - SNN（脉冲神经网络）
- **可微分渲染**
  - 逆向图形学
- **Digital Twins（数字孪生）**
  - 实时物理模拟

---

## 9. 学习资源推荐

### 9.1 官方文档
- NVIDIA CUDA Documentation
- AMD ROCm Documentation
- Vulkan Specification
- DirectX Documentation

### 9.2 在线课程
- NVIDIA DLI（Deep Learning Institute）
- Coursera: Heterogeneous Parallel Programming
- Udacity: Intro to Parallel Programming

### 9.3 经典书籍
- **Programming Massively Parallel Processors** (PMPP)
- **CUDA by Example**
- **Professional CUDA C Programming**
- **Real-Time Rendering**
- **Physically Based Rendering** (PBRT)

### 9.4 开源项目
- CUDA Samples
- PyTorch/TensorFlow 源码
- Blender (开源 3D 软件)
- GROMACS/LAMMPS

### 9.5 论文与会议
- SIGGRAPH (图形学)
- NeurIPS/ICML (机器学习)
- SC/PPoPP/IPDPS (高性能计算)
- arXiv.org

---

## 10. 实践项目建议

### 初级项目
1. 向量加法、矩阵乘法
2. 图像模糊、边缘检测
3. 简单的神经网络前向传播

### 中级项目
1. 优化的矩阵乘法（Tiling, 共享内存）
2. CNN 卷积层实现
3. 光线追踪渲染器
4. N-body 模拟

### 高级项目
1. Transformer 层优化
2. 分布式训练系统
3. 实时路径追踪引擎
4. GPU 数据库查询引擎

---

## 建议学习路径

**第一阶段（1-2个月）：基础入门**
- GPU 硬件架构
- CUDA C/C++ 基础
- 简单的并行算法

**第二阶段（2-3个月）：深入理解**
- 内存模型与优化
- 性能分析工具
- cuDNN/cuBLAS 库使用

**第三阶段（3-6个月）：专业方向**
- 选择深度学习 / 图形渲染 / 科学计算
- 深入学习相关框架和技术
- 完成中级实践项目

**第四阶段（6个月+）：高级应用**
- 多 GPU 编程
- 大规模系统优化
- 前沿技术研究
- 开源贡献