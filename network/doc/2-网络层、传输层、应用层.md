# GPU 集群网络架构完全指南
## 第二部分：网络层、传输层、应用层

---

## 目录
4. [网络层：路由和寻址](#4-网络层路由和寻址)
5. [传输层：通信协议](#5-传输层通信协议)
6. [通信库层：集合通信](#6-通信库层集合通信)
7. [应用层：训练框架](#7-应用层训练框架)

---

## 4. 网络层：路由和寻址

### 4.1 IP 地址规划

#### 网络分段架构

```
┌─────────────────────────────────────────────────────────────┐
│                  数据中心网络分段                            │
├────────────────┬────────────────┬───────────────────────────┤
│   网络类型     │   子网范围     │         用途               │
├────────────────┼────────────────┼───────────────────────────┤
│ 前端网络       │ 10.0.0.0/16   │ 数据加载、对外服务         │
│ (Frontend)     │ 65,536 地址   │ SSH 登录、HTTP API        │
├────────────────┼────────────────┼───────────────────────────┤
│ 后端网络       │192.168.0.0/16 │ GPU 通信、All-Reduce      │
│ (Backend)      │ 65,536 地址   │ 梯度同步、集合操作         │
├────────────────┼────────────────┼───────────────────────────┤
│ 管理网络       │ 172.16.0.0/16 │ IPMI, BMC                 │
│ (Management)   │ 65,536 地址   │ 监控、带外管理             │
├────────────────┼────────────────┼───────────────────────────┤
│ 存储网络       │ 10.1.0.0/16   │ NFS, Lustre, Ceph        │
│ (Storage)      │ 65,536 地址   │ 共享存储访问               │
└────────────────┴────────────────┴───────────────────────────┘
```

#### 单个节点的地址配置

```
节点示例: gpu-node-01
┌────────────────────────────────────────────────────┐
│  主机名: gpu-node-01.cluster.local                 │
├────────────────────────────────────────────────────┤
│                                                     │
│  ┌──────────────┐   IP: 10.0.1.10                 │
│  │ eth0 (前端)   │   网关: 10.0.0.1                │
│  │ 10/25 GbE    │   DNS: 10.0.0.53                │
│  └──────────────┘   路由: 默认网关                 │
│                                                     │
│  ┌──────────────┐   IP: 192.168.1.10              │
│  │ eth1 (后端)   │   无网关 (仅内部)               │
│  │ 100 GbE/IB   │   MTU: 9000 (Jumbo Frame)       │
│  └──────────────┘   RDMA: 启用                     │
│                                                     │
│  ┌──────────────┐   IP: 172.16.1.10               │
│  │ ipmi (管理)   │   独立 BMC 芯片                 │
│  │ 1 GbE        │   带外访问                       │
│  └──────────────┘   始终可达                       │
│                                                     │
│  ┌──────────────┐   IP: 10.1.1.10                 │
│  │ eth2 (存储)   │   挂载点: /data, /checkpoints   │
│  │ 10 GbE       │   协议: NFS v4                  │
│  └──────────────┘                                  │
└────────────────────────────────────────────────────┘
```

---

### 4.2 路由策略

#### Policy-Based Routing (基于策略的路由)

```python
# Linux 路由配置示例
# /etc/network/interfaces

# 前端网络 - 默认路由
auto eth0
iface eth0 inet static
    address 10.0.1.10
    netmask 255.255.0.0
    gateway 10.0.0.1
    dns-nameservers 10.0.0.53

# 后端网络 - 无默认网关，仅内部路由
auto eth1
iface eth1 inet static
    address 192.168.1.10
    netmask 255.255.0.0
    mtu 9000
    # 添加到路由表 100
    post-up ip route add 192.168.0.0/16 dev eth1 table 100
    post-up ip rule add from 192.168.1.10 table 100
    
# 存储网络
auto eth2
iface eth2 inet static
    address 10.1.1.10
    netmask 255.255.0.0
```

#### 流量路径示意

```
训练任务启动流程中的网络路径:

1. 加载训练代码和模型
   ┌──────┐  SSH/HTTP  ┌──────┐
   │ 用户 │ ────────> │ eth0 │ (前端网络)
   └──────┘           └──────┘
                         ↓
                    加载模型文件

2. 读取训练数据
   ┌──────┐  NFS Read  ┌──────┐
   │ GPU  │ <────────  │ eth2 │ (存储网络)
   └──────┘            └──────┘
                         ↑
                    /data/imagenet

3. GPU 间通信 (All-Reduce)
   ┌──────┐  NCCL/IB   ┌──────┐
   │ GPU0 │ <───────> │ eth1 │ (后端网络)
   └──────┘           └──────┘
                         ↕
                    192.168.x.x

4. 监控和日志
   ┌──────┐  Metrics   ┌──────┐
   │ 监控 │ <────────  │ eth0 │ (前端网络)
   └──────┘            └──────┘
```

---

### 4.3 VLAN 和网络隔离

#### VLAN 架构

```
┌─────────────────────────────────────────────────────────┐
│              物理交换机 (48 端口)                        │
│                                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │ VLAN 10 (前端)                                   │   │
│  │ 端口: 1-16   Tag: 10   子网: 10.0.0.0/16       │   │
│  └──────────────────────────────────────────────────┘   │
│                                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │ VLAN 20 (后端)                                   │   │
│  │ 端口: 17-32  Tag: 20   子网: 192.168.0.0/16    │   │
│  └──────────────────────────────────────────────────┘   │
│                                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │ VLAN 30 (管理)                                   │   │
│  │ 端口: 33-40  Tag: 30   子网: 172.16.0.0/16     │   │
│  └──────────────────────────────────────────────────┘   │
│                                                          │
│  ┌──────────────────────────────────────────────────┐   │
│  │ VLAN 40 (存储)                                   │   │
│  │ 端口: 41-48  Tag: 40   子网: 10.1.0.0/16       │   │
│  └──────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘

优点:
✓ 物理隔离 → 安全性高
✓ 广播域隔离 → 减少网络噪音
✓ 流量优先级 → QoS 策略
✓ 故障隔离 → 一个 VLAN 故障不影响其他
```

---

## 5. 传输层：通信协议

### 5.1 TCP/IP vs RDMA

#### 协议栈对比

```
┌──────────────────────────────────────────────────────────┐
│                     TCP/IP 协议栈                         │
├──────────────────────────────────────────────────────────┤
│  应用层     │  PyTorch, TensorFlow                       │
├─────────────┼────────────────────────────────────────────┤
│  传输层     │  TCP                                       │
│             │  - 可靠传输                                 │
│             │  - 拥塞控制                                 │
│             │  - 顺序保证                                 │
├─────────────┼────────────────────────────────────────────┤
│  网络层     │  IP                                        │
│             │  - 路由寻址                                 │
│             │  - 分片重组                                 │
├─────────────┼────────────────────────────────────────────┤
│  链路层     │  Ethernet                                  │
├─────────────┼────────────────────────────────────────────┤
│  物理层     │  网卡 (NIC)                                │
└─────────────┴────────────────────────────────────────────┘

                        vs

┌──────────────────────────────────────────────────────────┐
│                     RDMA 协议栈                           │
├──────────────────────────────────────────────────────────┤
│  应用层     │  PyTorch (NCCL)                            │
├─────────────┼────────────────────────────────────────────┤
│  RDMA Verbs │  libibverbs                                │
│             │  - 零拷贝                                   │
│             │  - 内核旁路                                 │
├─────────────┼────────────────────────────────────────────┤
│  传输层     │  InfiniBand / RoCE                         │
│             │  - 硬件可靠性                               │
│             │  - 流控制                                   │
├─────────────┼────────────────────────────────────────────┤
│  物理层     │  HCA 硬件                                  │
└─────────────┴────────────────────────────────────────────┘
```

#### 数据传输流程对比

**TCP/IP 传输流程：**
```
发送端:
┌─────────┐
│ 应用    │ 1. send() 系统调用
└────┬────┘
     │ 拷贝
┌────▼────┐
│ 内核缓冲 │ 2. TCP 封装，IP 封装
└────┬────┘
     │ 拷贝
┌────▼────┐
│ 网卡缓冲 │ 3. DMA 到网卡
└────┬────┘
     │
  ───▼─── 网络 ─────────────>

接收端:
     ◄─── 网络 ──────────────
     │
┌────▼────┐
│ 网卡缓冲 │ 1. DMA 从网卡
└────┬────┘
     │ 拷贝
┌────▼────┐
│ 内核缓冲 │ 2. TCP 解析，IP 解析
└────┬────┘
     │ 拷贝
┌────▼────┐
│ 应用    │ 3. recv() 系统调用
└─────────┘

总拷贝次数: 4 次
CPU 参与: 全程
延迟: 50-100 μs
```

**RDMA 传输流程：**
```
发送端:
┌─────────┐
│ 应用    │ 1. 注册内存
└────┬────┘
     │ 指针
┌────▼────┐
│  HCA   │ 2. 直接 DMA 读取应用内存
└────┬────┘
     │
  ───▼─── 网络 ─────────────>

接收端:
     ◄─── 网络 ──────────────
     │
┌────▼────┐
│  HCA   │ 1. 直接 DMA 写入应用内存
└────┬────┘
     │ 指针
┌────▼────┐
│ 应用    │ 2. 轮询完成
└─────────┘

总拷贝次数: 0 次 (零拷贝!)
CPU 参与: 最少
延迟: 1-2 μs
```

---

### 5.2 RDMA 操作类型

#### RDMA Verbs (操作原语)

```
┌────────────────────────────────────────────────────────┐
│                  RDMA 操作类型                          │
├─────────────┬──────────────────────────────────────────┤
│  操作类型   │              说明                         │
├─────────────┼──────────────────────────────────────────┤
│ RDMA Write  │ 单向写：本地 → 远程内存                  │
│             │ 对方 CPU 不感知                          │
│             │ 用途: 批量数据传输                        │
├─────────────┼──────────────────────────────────────────┤
│ RDMA Read   │ 单向读：远程内存 → 本地                  │
│             │ 对方 CPU 不感知                          │
│             │ 用途: 拉取数据                            │
├─────────────┼──────────────────────────────────────────┤
│ RDMA Send   │ 双向：需要接收方配合                      │
│ RDMA Recv   │ 有通知机制                                │
│             │ 用途: 同步、小消息                        │
├─────────────┼──────────────────────────────────────────┤
│ RDMA Atomic │ 原子操作：CAS, Fetch-Add                 │
│             │ 硬件保证原子性                            │
│             │ 用途: 分布式锁、计数器                    │
└─────────────┴──────────────────────────────────────────┘
```

#### NCCL 如何使用 RDMA

```python
# NCCL 内部使用 RDMA 的示意

# All-Reduce 操作
def nccl_all_reduce(tensor, world_size):
    """
    NCCL 将 All-Reduce 分解为多个 RDMA 操作
    """
    # 1. Ring All-Reduce 算法
    # 每个 GPU 向下一个 GPU 发送部分数据
    
    for step in range(world_size - 1):
        # 使用 RDMA Send/Recv
        send_chunk = tensor[send_idx]
        recv_chunk = rdma_recv(prev_rank)
        
        # 本地累加
        tensor[recv_idx] += recv_chunk
        
        # RDMA 发送到下一个
        rdma_send(send_chunk, next_rank)
    
    # 2. 完成后所有 GPU 有相同的部分结果
    
    # 3. 第二轮：传播完整结果
    for step in range(world_size - 1):
        # 继续 Ring 传播
        ...
    
    return tensor  # 所有 GPU 现在有相同的聚合结果
```

---

### 5.3 协议性能对比

#### 实测性能数据

```
测试场景: 2 节点，每节点 8x A100
消息大小: 1 GB
操作: All-Reduce

┌────────────┬─────────┬─────────┬─────────┬──────────┐
│  协议      │  带宽   │  延迟   │CPU占用 │  适用     │
├────────────┼─────────┼─────────┼─────────┼──────────┤
│ TCP/IP     │ 10 GB/s │ 100 μs │  80%   │ 通用网络 │
│ (10GbE)    │         │         │         │          │
├────────────┼─────────┼─────────┼─────────┼──────────┤
│ TCP/IP     │ 80 GB/s │  50 μs │  60%   │ 高速以太 │
│ (100GbE)   │         │         │         │          │
├────────────┼─────────┼─────────┼─────────┼──────────┤
│ RoCE v2    │ 90 GB/s │  10 μs │  20%   │ RDMA/以太│
│ (100GbE)   │         │         │         │          │
├────────────┼─────────┼─────────┼─────────┼──────────┤
│ InfiniBand │180 GB/s │  2 μs  │  5%    │ 专用HPC  │
│ HDR        │         │         │         │          │
├────────────┼─────────┼─────────┼─────────┼──────────┤
│ NVLink 3.0 │300 GB/s │  1 μs  │  1%    │ 节点内   │
│ (节点内)   │         │         │         │          │
└────────────┴─────────┴─────────┴─────────┴──────────┘
```

---

## 6. 通信库层：集合通信

### 6.1 NCCL 架构

#### NCCL 层次结构

```
┌─────────────────────────────────────────────────────────┐
│                    NCCL 架构                             │
│                                                          │
│  ┌────────────────────────────────────────────────┐    │
│  │          PyTorch / TensorFlow API              │    │
│  │  (torch.distributed, tf.distribute)            │    │
│  └──────────────────┬─────────────────────────────┘    │
│                     │                                    │
│  ┌──────────────────▼─────────────────────────────┐    │
│  │          NCCL API Layer                        │    │
│  │  ncclAllReduce(), ncclBroadcast(), ...        │    │
│  └──────────────────┬─────────────────────────────┘    │
│                     │                                    │
│  ┌──────────────────▼─────────────────────────────┐    │
│  │        NCCL Algorithms                         │    │
│  │  - Ring                                        │    │
│  │  - Tree                                        │    │
│  │  - Double Binary Tree                          │    │
│  └──┬─────────┬─────────┬─────────────────────────┘    │
│     │         │         │                               │
│  ┌──▼───┐ ┌──▼───┐ ┌───▼───┐                          │
│  │NVLink│ │ PCIe │ │ RDMA  │                          │
│  │Plugin│ │Plugin│ │Plugin │                          │
│  └──┬───┘ └──┬───┘ └───┬───┘                          │
│     │        │          │                               │
│  ┌──▼────────▼──────────▼──────┐                       │
│  │  Transport Layer             │                       │
│  │  (实际硬件通信)              │                       │
│  └──────────────────────────────┘                       │
└─────────────────────────────────────────────────────────┘
```

#### NCCL 自动拓扑检测

```
NCCL 启动时的检测流程:

1. 硬件拓扑扫描
   ├─ 检测 GPU 数量和型号
   ├─ 扫描 PCIe 拓扑
   ├─ 检测 NVLink 连接
   └─ 发现网络接口

2. 通信路径评估
   ├─ NVLink: 600 GB/s, 5 μs → 优先级 1
   ├─ PCIe:    16 GB/s, 100 μs → 优先级 2
   ├─ IB:      25 GB/s, 2 μs → 优先级 3
   └─ Socket:  1.25 GB/s, 50 μs → 优先级 4

3. 算法选择
   ├─ 小消息 (<1KB): Tree 算法
   ├─ 中消息 (1KB-1MB): Ring 算法
   └─ 大消息 (>1MB): Double Binary Tree

4. 生成通信计划
   └─ 每个操作优化路径
```

---

### 6.2 集合通信算法

#### Algorithm 1: Ring All-Reduce

```
8 GPU Ring All-Reduce 示意:

初始状态 (每个 GPU 有一个数据块):
GPU0: [A0]    GPU1: [A1]    GPU2: [A2]    GPU3: [A3]
GPU4: [A4]    GPU5: [A5]    GPU6: [A6]    GPU7: [A7]

形成 Ring:
GPU0 → GPU1 → GPU2 → GPU3 → GPU4 → GPU5 → GPU6 → GPU7 → GPU0
 ↑                                                         │
 └─────────────────────────────────────────────────────────┘

第 1 轮 (Reduce-Scatter):
Step 1: GPU0 发送 A0 给 GPU1，GPU1 计算 A0+A1
Step 2: GPU1 发送 A0+A1 给 GPU2，GPU2 计算 A0+A1+A2
...
Step 7: 完成，每个 GPU 拥有一个完整的累加块

第 2 轮 (All-Gather):
Step 1: 传播累加结果
...
Step 7: 完成，所有 GPU 拥有相同的完整结果

复杂度: O(N) 其中 N = GPU 数量
传输量: 2(N-1)/N * Data_Size ≈ 2 * Data_Size
优点: 带宽最优
缺点: 延迟较高 (2N 步)
```

#### Algorithm 2: Tree All-Reduce

```
8 GPU Binary Tree All-Reduce:

        GPU0 (根)
       /    \
    GPU1    GPU2
    /  \    /  \
GPU3 GPU4 GPU5 GPU6
   |
  GPU7

Up Phase (从叶到根):
1. GPU3,4,5,6,7 发送数据到父节点
2. GPU1,2 聚合并发送到 GPU0
3. GPU0 得到完整聚合结果

Down Phase (从根到叶):
1. GPU0 广播结果到 GPU1,2
2. GPU1,2 广播到子节点
3. 所有节点得到结果

复杂度: O(log N)
传输量: ~4 * Data_Size
优点: 延迟低 (2 log N 步)
缺点: 根节点带宽瓶颈
适用: 小消息 (<1KB)
```

---

### 6.3 案例：NCCL 在实际训练中的应用

#### 案例 1: ResNet-50 训练

```python
# 使用 PyTorch DDP 训练 ResNet-50

import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# 初始化 NCCL
dist.init_process_group(backend='nccl')

# 模型
model = torchvision.models.resnet50()
model = model.cuda()
model = DDP(model)  # DDP 包装，自动使用 NCCL

# 训练循环
for epoch in range(epochs):
    for batch in dataloader:
        images, labels = batch
        images, labels = images.cuda(), labels.cuda()
        
        # 前向传播 (各 GPU 独立)
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # 反向传播 (DDP 自动调用 NCCL All-Reduce 同步梯度)
        optimizer.zero_grad()
        loss.backward()  # ← 这里 NCCL 工作！
        
        optimizer.step()

# NCCL 做了什么？
# 1. loss.backward() 计算梯度
# 2. DDP 检测到梯度就绪
# 3. 后台线程调用 ncclAllReduce(gradients)
# 4. 所有 GPU 梯度同步
# 5. optimizer.step() 更新参数 (所有 GPU 更新相同)
```

#### 通信时间分析

```
ResNet-50 训练 (8x V100, Batch=32/GPU):

每次迭代时间分解:
├─ 数据加载: 10 ms (前端网络)
├─ 前向传播: 50 ms (GPU 计算)
├─ 反向传播: 80 ms (GPU 计算)
│   └─ 其中梯度同步: 15 ms (NCCL All-Reduce)
└─ 参数更新: 5 ms (GPU 计算)

总时间: 145 ms
通信占比: 15/145 = 10.3%

网络影响:
├─ NVLink (节点内): 5 ms → 总时间 135 ms
├─ InfiniBand (节点间): 15 ms → 总时间 145 ms
└─ 10GbE (节点间): 80 ms → 总时间 210 ms

结论: 网络对大模型训练影响显著！
```

---

## 7. 应用层：训练框架

### 7.1 PyTorch 分布式架构

#### PyTorch Distributed 层次

```
┌─────────────────────────────────────────────────────────┐
│                PyTorch 分布式生态                        │
│                                                          │
│  ┌────────────────────────────────────────────────┐    │
│  │  torch.nn.parallel.DistributedDataParallel     │    │
│  │  (DDP - 数据并行)                              │    │
│  └──────────────────┬─────────────────────────────┘    │
│                     │                                    │
│  ┌──────────────────▼─────────────────────────────┐    │
│  │  torch.distributed                             │    │
│  │  - init_process_group()                        │    │
│  │  - all_reduce(), broadcast(), ...             │    │
│  └──────────────────┬─────────────────────────────┘    │
│                     │                                    │
│  ┌──────────────────▼─────────────────────────────┐    │
│  │  Backend 选择                                  │    │
│  │  ┌──────┐  ┌──────┐  ┌──────┐                │    │
│  │  │ NCCL │  │ Gloo │  │ MPI  │                │    │
│  │  └───┬──┘  └───┬──┘  └───┬──┘                │    │
│  └──────┼─────────┼─────────┼─────────────────────┘    │
│         │         │         │                           │
│      GPU通信   CPU通信   通用通信                       │
└─────────────────────────────────────────────────────────┘
```

#### Backend 对比

```
┌──────────┬─────────────┬───────────┬──────────────┐
│ Backend  │   设备      │   性能    │    适用      │
├──────────┼─────────────┼───────────┼──────────────┤
│ NCCL     │ GPU (CUDA)  │  最快     │ GPU 训练     │
│          │             │           │ 推荐首选     │
├──────────┼─────────────┼───────────┼──────────────┤
│ Gloo     │ CPU / GPU   │  中等     │ CPU 训练     │
│          │             │           │ 研究/调试    │
├──────────┼─────────────┼───────────┼──────────────┤
│ MPI      │ CPU / GPU   │  可配置   │ HPC 环境     │
│          │             │           │ 自定义通信   │
└──────────┴─────────────┴───────────┴──────────────┘
```

---

### 7.2 完整训练案例

#### 端到端案例：大语言模型预训练

```python
"""
案例: 在 256 GPU (32 节点 x 8 GPU) 上预训练 GPT-3 (175B 参数)
网络: InfiniBand HDR (200 Gbps)
"""

import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# ==================== 网络配置 ====================
import os

# 后端网络: InfiniBand
os.environ['NCCL_SOCKET_IFNAME'] = 'ib0'
os.environ['NCCL_IB_HCA'] = 'mlx5_0'
os.environ['NCCL_DEBUG'] = 'INFO'

# 优化
os.environ['NCCL_BUFFSIZE'] = '8388608'  # 8MB
os.environ['NCCL_NTHREADS'] = '16'

# ==================== 初始化 ====================
# 节点内 rank (0-7)
local_rank = int(os.environ['LOCAL_RANK'])

# 全局 rank (0-255)
global_rank = int(os.environ['RANK'])

# 总 GPU 数
world_size = 256

# 初始化 NCCL
dist.init_process_group(
    backend='nccl',
    init_method='env://',  # 从环境变量读取 MASTER_ADDR, MASTER_PORT
    world_size=world_size,
    rank=global_rank
)

torch.cuda.set_device(local_rank)

# ==================== 模型 ====================
# GPT-3 175B 参数
from transformers import GPT2Config, GPT2LMHeadModel

config = GPT2Config(
    vocab_size=50257,
    n_positions=2048,
    n_embd=12288,      # 隐藏层维度
    n_layer=96,        # Transformer 层数
    n_head=96,         # 注意力头数
)

model = GPT2LMHeadModel(config)
model = model.cuda(local_rank)

# DDP 包装
model = DDP(
    model,
    device_ids=[local_rank],
    output_device=local_rank,
    bucket_cap_mb=200,  # 200MB 梯度桶
    find_unused_parameters=False,
)

# ==================== 数据 ====================
# 前端网络: 从共享存储加载数据
from torch.utils.data import DataLoader, DistributedSampler

dataset = load_dataset()  # 加载训练数据
sampler = DistributedSampler(
    dataset,
    num_replicas=world_size,
    rank=global_rank,
    shuffle=True
)

dataloader = DataLoader(
    dataset,
    batch_size=2,  # Micro-batch per GPU
    sampler=sampler,
    num_workers=4,  # 数据加载线程
    pin_memory=True,  # 加速 CPU→GPU 传输
    prefetch_factor=2,
)

# ==================== 训练循环 ====================
from torch.cuda.amp import autocast, GradScaler

optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
scaler = GradScaler()  # 混合精度

gradient_accumulation_steps = 16  # 梯度累积

for epoch in range(num_epochs):
    sampler.set_epoch(epoch)
    
    for step, batch in enumerate(dataloader):
        # 数据传输 (前端网络)
        input_ids = batch['input_ids'].cuda(local_rank)
        attention_mask = batch['attention_mask'].cuda(local_rank)
        
        # 混合精度前向
        with autocast():
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=input_ids
            )
            loss = outputs.loss / gradient_accumulation_steps
        
        # 反向传播
        scaler.scale(loss).backward()
        
        # 每 N 步更新一次 (减少通信)
        if (step + 1) % gradient_accumulation_steps == 0:
            # 梯度裁剪
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            
            # 参数更新
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
            
            # 日志 (只在 rank 0)
            if global_rank == 0:
                print(f"Epoch {epoch}, Step {step}, Loss: {loss.item()}")

# ==================== 性能分析 ====================
"""
通信分析:

模型大小: 175B 参数 × 4 字节/参数 = 700 GB
梯度大小: 700 GB (FP32) 或 350 GB (FP16)

每次 All-Reduce:
├─ 数据量: 350 GB (FP16)
├─ 算法: NCCL Ring All-Reduce
├─ 理论时间: 350 GB / 200 Gbps / 256 GPUs ≈ 14 ms
├─ 实际时间: ~50 ms (考虑延迟、协调)
└─ 占总时间: 50ms / 5000ms ≈ 1%

网络带宽需求:
├─ 前端网络: 10 GB/s (数据加载，256 节点共享)
├─ 后端网络: 200 Gbps × 256 ports = 51.2 Tbps 总带宽
└─ 存储网络: 100 GB/s (checkpoint 保存)

为什么需要 InfiniBand？
如果用 10 GbE:
├─ 梯度同步时间: 350 GB / 10 Gbps = 280 秒！
├─ 完全不可用
└─ InfiniBand 是必须的
"""
```

---

### 7.3 网络监控和调试

#### 实时监控工具

```bash
# 1. 监控 NCCL 通信
export NCCL_DEBUG=INFO
export NCCL_DEBUG_SUBSYS=ALL

# 2. 监控网络流量
# InfiniBand
ibstat                    # 查看 IB 状态
ibdiagnet                 # IB 诊断
perfquery                 # IB 性能计数器

# 以太网
iftop -i eth1             # 实时流量
nethogs eth1              # 按进程统计
bmon -p eth1              # 带宽监控

# 3. 监控 GPU 通信
nvidia-smi nvlink -s      # NVLink 状态
nvidia-smi nvlink -g 0    # GPU 0 的 NVLink 拓扑
dcgmi profile --pause     # DCGM 监控

# 4. 性能分析
nsys profile -o nccl_trace python train.py  # Nsight Systems
ncu --set full python train.py              # Nsight Compute
```

#### NCCL 性能测试

```bash
# NCCL Tests
git clone https://github.com/NVIDIA/nccl-tests.git
cd nccl-tests && make

# 单机测试
./build/all_reduce_perf -b 8 -e 8G -f 2 -g 8

# 多机测试 (256 GPU)
mpirun -np 256 \
    -H node01:8,node02:8,...,node32:8 \
    -bind-to none -map-by slot \
    -x NCCL_DEBUG=INFO \
    -x NCCL_SOCKET_IFNAME=ib0 \
    ./build/all_reduce_perf -b 8 -e 8G -f 2

# 输出示例:
# Size      Time    AlgBW   BusBW
# 8B        10us    0.8GB/s  0.8GB/s
# 1KB       12us    85MB/s   85MB/s
# 1MB       100us   10GB/s   19GB/s
# 1GB       50ms    20GB/s   38GB/s
# 8GB       350ms   23GB/s   43GB/s
```

---

## 小结

### 完整通信栈回顾

```
┌─────────────────────────────────────────────────────┐
│  应用: PyTorch DDP 训练                             │
│  ↓ torch.distributed API                           │
├─────────────────────────────────────────────────────┤
│  通信库: NCCL                                       │
│  ↓ ncclAllReduce(), Ring/Tree 算法                 │
├─────────────────────────────────────────────────────┤
│  传输: RDMA (InfiniBand) / TCP/IP                  │
│  ↓ 零拷贝 / 可靠传输                                │
├─────────────────────────────────────────────────────┤
│  网络: IP 路由，VLAN 隔离                           │
│  ↓ 后端网络 192.168.x.x                            │
├─────────────────────────────────────────────────────┤
│  链路: PCIe / NVLink / InfiniBand Fabric           │
│  ↓ 点对点连接                                       │
├─────────────────────────────────────────────────────┤
│  物理: GPU, HCA, Switch, Cable                     │
│  ↓ 硬件执行                                         │
└─────────────────────────────────────────────────────┘
```

### 关键takeaway

1. **分层设计**: 每层有明确职责
2. **自动优化**: NCCL 自动选择最优路径
3. **网络隔离**: 前端、后端、管理网络分离
4. **性能瓶颈**: 大规模训练，网络是关键
5. **成本权衡**: InfiniBand vs 以太网

---

[下一部分：典型部署架构和最佳实践 →]