# 分布式训练深度剖析：ResNet-50 案例
## 案例：4 GPU 数据并行训练 ResNet-50

---

## 目录
1. [模型和场景设置](#1-模型和场景设置)
2. [参数存储方式](#2-参数存储方式)
3. [单次迭代完整时间线](#3-单次迭代完整时间线)
4. [每张卡的详细状态](#4-每张卡的详细状态)
5. [NCCL 通信详解](#5-nccl-通信详解)
6. [内存布局分析](#6-内存布局分析)
7. [完整代码示例](#7-完整代码示例)

---

## 1. 模型和场景设置

### 1.1 训练配置

```python
模型: ResNet-50
参数量: 25.6M (约 102MB in FP32, 51MB in FP16)
任务: ImageNet 分类

训练配置:
├─ GPU 数量: 4 张 (GPU 0, 1, 2, 3)
├─ Batch Size: 128 (每张卡 32)
├─ 优化器: SGD with Momentum
├─ 学习率: 0.1
└─ 并行模式: 数据并行 (DistributedDataParallel)

环境:
├─ 节点: 单机 4 GPU
├─ 互连: PCIe Gen3 (16 GB/s)
├─ 通信库: NCCL
└─ 框架: PyTorch
```

### 1.2 ResNet-50 架构

```
ResNet-50 结构:
┌────────────────────────────────────────┐
│ Input (3x224x224)                      │
└──────────────┬─────────────────────────┘
               │
┌──────────────▼─────────────────────────┐
│ conv1 (7x7, stride=2)                  │
│ 参数: 9,408 (约 37KB)                  │
└──────────────┬─────────────────────────┘
               │
┌──────────────▼─────────────────────────┐
│ layer1 (3 个 Bottleneck 块)            │
│ 参数: 215,808 (约 863KB)               │
└──────────────┬─────────────────────────┘
               │
┌──────────────▼─────────────────────────┐
│ layer2 (4 个 Bottleneck 块)            │
│ 参数: 1,219,584 (约 4.9MB)             │
└──────────────┬─────────────────────────┘
               │
┌──────────────▼─────────────────────────┐
│ layer3 (6 个 Bottleneck 块)            │
│ 参数: 7,098,368 (约 28.4MB)            │
└──────────────┬─────────────────────────┘
               │
┌──────────────▼─────────────────────────┐
│ layer4 (3 个 Bottleneck 块)            │
│ 参数: 14,964,736 (约 59.9MB)           │
└──────────────┬─────────────────────────┘
               │
┌──────────────▼─────────────────────────┐
│ fc (全连接层)                           │
│ 参数: 2,048,000 (约 8.2MB)             │
└──────────────┬─────────────────────────┘
               │
               ▼
          Output (1000 类)

总参数: 25,557,032 ≈ 25.6M
FP32 大小: 102.2 MB
FP16 大小: 51.1 MB
```

---

## 2. 参数存储方式

### 2.1 数据并行 (DDP) - 参数复制

在数据并行模式下，**每张 GPU 都有完整模型的一份拷贝**。

```
┌─────────────────────────────────────────────────────────────┐
│                    参数存储示意图                            │
│                                                              │
│  GPU 0                    GPU 1                             │
│  ┌──────────────────┐    ┌──────────────────┐              │
│  │ ResNet-50 完整   │    │ ResNet-50 完整   │              │
│  │ 参数 (102MB)     │    │ 参数 (102MB)     │              │
│  │                  │    │                  │              │
│  │ conv1: 37KB     │    │ conv1: 37KB     │              │
│  │ layer1: 863KB   │    │ layer1: 863KB   │              │
│  │ layer2: 4.9MB   │    │ layer2: 4.9MB   │              │
│  │ layer3: 28.4MB  │    │ layer3: 28.4MB  │              │
│  │ layer4: 59.9MB  │    │ layer4: 59.9MB  │              │
│  │ fc: 8.2MB       │    │ fc: 8.2MB       │              │
│  └──────────────────┘    └──────────────────┘              │
│                                                              │
│  GPU 2                    GPU 3                             │
│  ┌──────────────────┐    ┌──────────────────┐              │
│  │ ResNet-50 完整   │    │ ResNet-50 完整   │              │
│  │ 参数 (102MB)     │    │ 参数 (102MB)     │              │
│  │                  │    │                  │              │
│  │ conv1: 37KB     │    │ conv1: 37KB     │              │
│  │ layer1: 863KB   │    │ layer1: 863KB   │              │
│  │ layer2: 4.9MB   │    │ layer2: 4.9MB   │              │
│  │ layer3: 28.4MB  │    │ layer3: 28.4MB  │              │
│  │ layer4: 59.9MB  │    │ layer4: 59.9MB  │              │
│  │ fc: 8.2MB       │    │ fc: 8.2MB       │              │
│  └──────────────────┘    └──────────────────┘              │
│                                                              │
│  关键点：                                                    │
│  ✓ 每张卡有完整的模型副本                                   │
│  ✓ 参数初始化后完全相同（broadcast from rank 0）           │
│  ✓ 训练过程中参数保持同步（通过梯度 All-Reduce）           │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 数据分片

虽然参数是完整复制的，但**数据是分片的**：

```
完整 Batch (128 张图片):
┌────────────────────────────────────────────────────────┐
│ [Img 0 - Img 127]                                      │
└────────────────────────────────────────────────────────┘
                       │
                       │ DistributedSampler 分片
                       ▼
    ┌──────────┬──────────┬──────────┬──────────┐
    │  GPU 0   │  GPU 1   │  GPU 2   │  GPU 3   │
    ├──────────┼──────────┼──────────┼──────────┤
    │ Img 0-31 │ Img 32-63│ Img 64-95│ Img 96-127│
    │ (32张)   │ (32张)   │ (32张)   │ (32张)    │
    └──────────┴──────────┴──────────┴──────────┘

每张卡:
├─ 输入数据: 32x3x224x224 ≈ 19 MB
├─ 标签: 32 个 (可忽略)
└─ 独立处理自己的 mini-batch
```

### 2.3 梯度和优化器状态

```
每张 GPU 的完整内存布局:

┌─────────────────────────────────────────────────────────┐
│                    GPU 0 显存 (16GB)                     │
├─────────────────────────────────────────────────────────┤
│                                                          │
│ 1. 模型参数 (Parameters)                                │
│    - 大小: 102 MB (FP32) 或 51 MB (FP16)               │
│    - 内容: 25.6M 参数                                   │
│    - 状态: 所有 GPU 相同                                │
│                                                          │
│ 2. 梯度 (Gradients)                                     │
│    - 大小: 102 MB (FP32) 或 51 MB (FP16)               │
│    - 内容: 每个参数对应的梯度                           │
│    - 状态: 反向传播后各 GPU 不同，All-Reduce 后相同    │
│                                                          │
│ 3. 优化器状态 (Optimizer States)                       │
│    - Momentum: 102 MB                                   │
│    - 大小: 102 MB (SGD) 或 306 MB (Adam: m + v + params)│
│    - 状态: 所有 GPU 相同                                │
│                                                          │
│ 4. 激活值 (Activations)                                │
│    - 大小: ~500 MB (取决于 batch size)                 │
│    - 内容: 前向传播的中间结果                           │
│    - 状态: 各 GPU 不同（处理不同数据）                  │
│                                                          │
│ 5. 输入数据 (Input Batch)                              │
│    - 大小: 32x3x224x224 ≈ 19 MB                        │
│    - 状态: 各 GPU 不同                                  │
│                                                          │
├─────────────────────────────────────────────────────────┤
│ 总显存占用: ~850 MB (FP32) 或 ~630 MB (FP16)           │
└─────────────────────────────────────────────────────────┘

GPU 1, 2, 3 的布局完全相同
```

---

## 3. 单次迭代完整时间线

### 3.1 时间线总览

```
单次训练迭代 (约 50ms):

时间轴 (ms):
0────10───20───30───40───50
│    │    │    │    │    │
▼    ▼    ▼    ▼    ▼    ▼

┌────────────────────────────────────────────────────┐
│ Phase 1: 数据加载 (0-5ms)                          │
│ 所有 GPU 并行加载各自的 mini-batch                 │
└────────────────────────────────────────────────────┘
     │
     ▼
┌────────────────────────────────────────────────────┐
│ Phase 2: 前向传播 (5-20ms)                         │
│ 各 GPU 独立计算，无通信                            │
└────────────────────────────────────────────────────┘
     │
     ▼
┌────────────────────────────────────────────────────┐
│ Phase 3: 计算损失 (20-21ms)                        │
│ 各 GPU 独立计算 loss                               │
└────────────────────────────────────────────────────┘
     │
     ▼
┌────────────────────────────────────────────────────┐
│ Phase 4: 反向传播 + 梯度同步 (21-45ms)             │
│ ├─ 反向计算梯度 (21-40ms)                         │
│ │  各层反向传播，边算边通信                        │
│ └─ NCCL All-Reduce (与反向传播重叠)               │
│     梯度就绪立即同步                                │
└────────────────────────────────────────────────────┘
     │
     ▼
┌────────────────────────────────────────────────────┐
│ Phase 5: 参数更新 (45-50ms)                        │
│ optimizer.step() - 各 GPU 独立更新                 │
│ 因为梯度相同，更新后参数也相同                      │
└────────────────────────────────────────────────────┘
```

### 3.2 详细时间线 (毫秒级)

```
时刻 T0 (0ms): 迭代开始
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ 加载数据     │ 加载数据     │ 加载数据     │ 加载数据
│ Img 0-31     │ Img 32-63    │ Img 64-95    │ Img 96-127
│              │              │              │
│ CPU→GPU      │ CPU→GPU      │ CPU→GPU      │ CPU→GPU
│ 传输         │ 传输         │ 传输         │ 传输
│              │              │              │


时刻 T1 (5ms): 前向传播开始
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ conv1        │ conv1        │ conv1        │ conv1
│ ↓            │ ↓            │ ↓            │ ↓
│ layer1       │ layer1       │ layer1       │ layer1
│ ↓            │ ↓            │ ↓            │ ↓
│ layer2       │ layer2       │ layer2       │ layer2
│ ↓            │ ↓            │ ↓            │ ↓
│ layer3       │ layer3       │ layer3       │ layer3
│ ↓            │ ↓            │ ↓            │ ↓
│ layer4       │ layer4       │ layer4       │ layer4
│ ↓            │ ↓            │ ↓            │ ↓
│ fc           │ fc           │ fc           │ fc
│              │              │              │
│ 无 GPU 间通信！各自独立计算                │


时刻 T2 (20ms): 计算损失
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ loss_0       │ loss_1       │ loss_2       │ loss_3
│ = 2.3        │ = 2.1        │ = 2.4        │ = 2.2
│              │              │              │
│ 损失值不同（数据不同）                      │


时刻 T3 (21ms): 反向传播开始
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ ∂loss/∂fc    │ ∂loss/∂fc    │ ∂loss/∂fc    │ ∂loss/∂fc
│ ↓            │ ↓            │ ↓            │ ↓
│ ∂fc/∂layer4  │ ∂fc/∂layer4  │ ∂fc/∂layer4  │ ∂fc/∂layer4
│              │              │              │
│ 开始反向传播，计算每层梯度                  │


时刻 T4 (35ms): 第一批梯度就绪 (fc 层)
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ grad_fc 就绪 │ grad_fc 就绪 │ grad_fc 就绪 │ grad_fc 就绪
│  [梯度值]    │  [梯度值]    │  [梯度值]    │  [梯度值]
│    ↓         │    ↓         │    ↓         │    ↓
│    └─────────┴──────┬───────┴──────────────┘
│                     ▼
│              NCCL All-Reduce
│           (在后台异步执行！)
│                     │
│    ┌────────────────┴────────────────┐
│    ▼         ▼         ▼              ▼
│ grad_fc_avg grad_fc_avg grad_fc_avg grad_fc_avg
│ (平均值)   (平均值)   (平均值)    (平均值)
│              │              │              │
│ 继续反向     │ 继续反向     │ 继续反向     │ 继续反向
│ layer4       │ layer4       │ layer4       │ layer4


时刻 T5 (40ms): 所有梯度同步完成
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ 所有层的梯度 │ 所有层的梯度 │ 所有层的梯度 │ 所有层的梯度
│ 已同步       │ 已同步       │ 已同步       │ 已同步
│              │              │              │
│ grad[conv1]  │ grad[conv1]  │ grad[conv1]  │ grad[conv1]
│ grad[layer1] │ grad[layer1] │ grad[layer1] │ grad[layer1]
│ grad[layer2] │ grad[layer2] │ grad[layer2] │ grad[layer2]
│ grad[layer3] │ grad[layer3] │ grad[layer3] │ grad[layer3]
│ grad[layer4] │ grad[layer4] │ grad[layer4] │ grad[layer4]
│ grad[fc]     │ grad[fc]     │ grad[fc]     │ grad[fc]
│              │              │              │
│ 所有 GPU 的梯度现在完全相同！               │


时刻 T6 (45ms): 参数更新
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ optimizer.step()                                    │
│              │              │              │
│ 对于每个参数 w:                                     │
│ w = w - lr * grad[w]                                │
│              │              │              │
│ param[conv1] │ param[conv1] │ param[conv1] │ param[conv1]
│  ← 更新      │  ← 更新      │  ← 更新      │  ← 更新
│              │              │              │
│ 因为梯度相同，更新后的参数也相同！          │


时刻 T7 (50ms): 迭代结束
════════════════════════════════════════════════════════

GPU 0          GPU 1          GPU 2          GPU 3
│              │              │              │
│ 参数已更新   │ 参数已更新   │ 参数已更新   │ 参数已更新
│ 准备下一批   │ 准备下一批   │ 准备下一批   │ 准备下一批
│              │              │              │
│ 循环往复...                                         │
```

---

## 4. 每张卡的详细状态

### 4.1 GPU 0 的完整工作流程

```python
# =============== GPU 0 的视角 ===============

# T0: 数据加载
"""
从 DataLoader 获取数据:
- 输入: images[0:32]   # 前 32 张图片
- 标签: labels[0:32]
- 内存位置: CPU
- 传输到 GPU 0
"""
images_gpu0 = images[0:32].cuda(0)  # 19 MB
labels_gpu0 = labels[0:32].cuda(0)

# T1-T2: 前向传播 (15ms)
"""
通过完整的 ResNet-50 网络:

输入: [32, 3, 224, 224]
  ↓
conv1: [32, 64, 112, 112]
  ↓ (激活值占用显存)
layer1: [32, 256, 56, 56]
  ↓ (激活值占用显存)
layer2: [32, 512, 28, 28]
  ↓ (激活值占用显存)
layer3: [32, 1024, 14, 14]
  ↓ (激活值占用显存)
layer4: [32, 2048, 7, 7]
  ↓
avgpool: [32, 2048, 1, 1]
  ↓
fc: [32, 1000]

输出: logits_gpu0 [32, 1000]

关键点:
- GPU 0 只处理自己的 32 张图
- 不知道其他 GPU 在做什么
- 所有中间激活值保存在 GPU 0 显存
- 参数从 GPU 0 的本地副本读取
"""
output_gpu0 = model(images_gpu0)  # model 是完整的 ResNet-50

# T2: 计算损失
"""
只用 GPU 0 的数据计算损失:
"""
loss_gpu0 = criterion(output_gpu0, labels_gpu0)
# loss_gpu0 = 2.3 (仅 GPU 0 的数据，不是全局损失)

# T3-T5: 反向传播 + 梯度同步 (19ms)
"""
反向传播计算梯度:

第 1 步: 计算 fc 层梯度
grad_fc_gpu0 = ∂loss_gpu0/∂fc
# 大小: [1000, 2048] = 8.2 MB

第 2 步: DDP 自动触发 NCCL All-Reduce
# fc 层梯度就绪 → 立即加入通信队列
# NCCL 在后台线程执行:
#   1. GPU 0 发送 grad_fc_gpu0 给其他 GPU
#   2. GPU 0 接收其他 GPU 的 grad_fc
#   3. 求平均: grad_fc = (grad_fc_gpu0 + grad_fc_gpu1 + 
#                          grad_fc_gpu2 + grad_fc_gpu3) / 4
# 时间: ~2ms (并行于继续反向传播)

第 3 步: 继续反向传播 layer4
grad_layer4_gpu0 = ∂loss/∂layer4
# 大小: ~60 MB

第 4 步: layer4 梯度就绪 → All-Reduce
# 同样的过程...

第 5 步: 重复 layer3, layer2, layer1, conv1
...

最终状态:
- GPU 0 的所有梯度都是 4 个 GPU 的平均值
- grad[w]_gpu0 = (grad[w]_gpu0_local + grad[w]_gpu1_local + 
                   grad[w]_gpu2_local + grad[w]_gpu3_local) / 4
"""
loss_gpu0.backward()  # DDP 自动处理 All-Reduce

# T6: 参数更新 (5ms)
"""
使用同步后的梯度更新参数:

对于每个参数 w:
  w_new = w_old - lr * grad[w]
  
因为所有 GPU 的 grad[w] 相同，所以更新后的参数也相同
"""
optimizer.step()

# T7: 清零梯度
optimizer.zero_grad()

# GPU 0 完成一次迭代！
```

### 4.2 GPU 1, 2, 3 的工作流程

```python
# =============== GPU 1 的视角 ===============
# 与 GPU 0 完全并行执行，流程相同

# 唯一的区别:
images_gpu1 = images[32:64].cuda(1)  # 不同的数据
labels_gpu1 = labels[32:64].cuda(1)

output_gpu1 = model(images_gpu1)    # 相同的模型
loss_gpu1 = criterion(output_gpu1, labels_gpu1)  # loss_gpu1 = 2.1

loss_gpu1.backward()  # 参与相同的 All-Reduce

optimizer.step()      # 同样的更新

# GPU 2 和 GPU 3 完全类似，只是数据切片不同
```

---

## 5. NCCL 通信详解

### 5.1 梯度同步的 Ring All-Reduce 算法

```
场景: 同步 fc 层梯度 (8.2 MB)

初始状态 (各 GPU 本地梯度):
GPU 0: grad_0 = [0.5, 0.3, 0.8, ...]  # 从自己的数据算出
GPU 1: grad_1 = [0.6, 0.2, 0.7, ...]  # 从自己的数据算出
GPU 2: grad_2 = [0.4, 0.4, 0.9, ...]
GPU 3: grad_3 = [0.7, 0.1, 0.6, ...]

目标: 所有 GPU 得到平均梯度
grad_avg = (grad_0 + grad_1 + grad_2 + grad_3) / 4

Ring All-Reduce 步骤:

第 1 轮: Reduce-Scatter
────────────────────────────────────────────────
将梯度分成 4 块 (每块 2.05 MB):

GPU 0: [chunk_0 | chunk_1 | chunk_2 | chunk_3]
GPU 1: [chunk_0 | chunk_1 | chunk_2 | chunk_3]
GPU 2: [chunk_0 | chunk_1 | chunk_2 | chunk_3]
GPU 3: [chunk_0 | chunk_1 | chunk_2 | chunk_3]

Step 1: 形成 Ring
GPU 0 → GPU 1 → GPU 2 → GPU 3 → GPU 0

Step 2-4: 每个 GPU 累加邻居的一个 chunk
(3 步后，每个 GPU 负责一个完整累加的 chunk)

第 2 轮: All-Gather
────────────────────────────────────────────────
Step 5-7: 传播累加完成的 chunks
(3 步后，所有 GPU 都有完整的平均梯度)

最终状态:
GPU 0: grad_avg = [avg_0, avg_1, avg_2, avg_3]
GPU 1: grad_avg = [avg_0, avg_1, avg_2, avg_3]  # 相同
GPU 2: grad_avg = [avg_0, avg_1, avg_2, avg_3]  # 相同
GPU 3: grad_avg = [avg_0, avg_1, avg_2, avg_3]  # 相同

通信量: 2(N-1)/N × Data_Size
       = 2(4-1)/4 × 8.2MB 
       = 12.3 MB (每个 GPU)

时间: 12.3 MB / 16 GB/s (PCIe) ≈ 0.8 ms
```

### 5.2 梯度分桶 (Gradient Bucketing)

```
DDP 不是等所有梯度都算完才 All-Reduce，而是分批进行:

梯度桶划分 (bucket_cap_mb = 25):
┌────────────────────────────────────────────────┐
│ Bucket 0 (25 MB):                              │
│ - fc 层梯度 (8.2 MB)                           │
│ - layer4 末尾几层 (16.8 MB)                    │
│ ─────────────────────────────────────────────  │
│ 第一个就绪 → 立即 All-Reduce                   │
└────────────────────────────────────────────────┘

┌────────────────────────────────────────────────┐
│ Bucket 1 (25 MB):                              │
│ - layer4 中间部分                               │
│ ─────────────────────────────────────────────  │
│ 就绪 → All-Reduce                              │
└────────────────────────────────────────────────┘

┌────────────────────────────────────────────────┐
│ Bucket 2 (25 MB):                              │
│ - layer3 梯度                                   │
└────────────────────────────────────────────────┘

... 继续

这样反向传播和通信可以重叠:
┌──────────────────────────────────────────────┐
│ 时间线:                                      │
│                                              │
│ GPU 计算:  [layer4] [layer3] [layer2] ...   │
│            ───────  ───────  ───────         │
│                                              │
│ NCCL 通信:    [bucket0][bucket1][bucket2]... │
│               ────────────────────────        │
│                                              │
│ 重叠！通信在后台进行                         │
└──────────────────────────────────────────────┘
```

### 5.3 通信开销分析

```
ResNet-50 单次迭代通信量:

总梯度大小: 102 MB (FP32)
GPU 数量: 4

每个 GPU 的通信量:
  All-Reduce: 2(N-1)/N × 102 MB 
            = 2 × 3/4 × 102 MB
            = 153 MB

通信时间 (PCIe Gen3, 16 GB/s):
  理论时间: 153 MB / 16 GB/s = 9.5 ms
  实际时间: ~15 ms (加上延迟、协议开销)

与计算时间对比:
  前向传播: 15 ms
  反向传播: 25 ms (纯计算部分)
  通信: 15 ms (与反向重叠约 80%)
  
实际通信占比:
  纯通信时间: 15 × (1 - 0.8) = 3 ms
  占总时间: 3/50 = 6%

结论: 通信不是瓶颈！(因为重叠)
```

---

## 6. 内存布局分析

### 6.1 显存占用时间轴

```
GPU 0 显存占用 (16 GB 总容量):

迭代开始 (T0):
┌─────────────────────────────────────────────┐
│ 已占用 (持久):                              │
│ ├─ 模型参数: 102 MB                        │
│ ├─ 优化器状态: 102 MB (Momentum)           │
│ └─ PyTorch 缓存: 200 MB                    │
│ 总计: 404 MB                               │
└─────────────────────────────────────────────┘

数据加载 (T0-T1):
┌─────────────────────────────────────────────┐
│ + 输入数据: 19 MB                           │
│ 总计: 423 MB                               │
└─────────────────────────────────────────────┘

前向传播 (T1-T2):
┌─────────────────────────────────────────────┐
│ + 激活值:                                   │
│   ├─ conv1: 50 MB                          │
│   ├─ layer1: 100 MB                        │
│   ├─ layer2: 80 MB                         │
│   ├─ layer3: 150 MB                        │
│   ├─ layer4: 100 MB                        │
│   └─ fc: 10 MB                             │
│ 激活值总计: 490 MB                         │
│                                             │
│ 总计: 913 MB                               │
└─────────────────────────────────────────────┘

反向传播 (T3-T5):
┌─────────────────────────────────────────────┐
│ + 梯度: 102 MB                             │
│ (激活值逐渐释放)                            │
│                                             │
│ 峰值总计: 1015 MB                          │
└─────────────────────────────────────────────┘

参数更新 (T6):
┌─────────────────────────────────────────────┐
│ 激活值已释放                                │
│ 梯度保留                                    │
│                                             │
│ 总计: 608 MB                               │
└─────────────────────────────────────────────┘

清零梯度 (T7):
┌─────────────────────────────────────────────┐
│ 回到初始状态                                │
│ 总计: 404 MB                               │
└─────────────────────────────────────────────┘

峰值显存: ~1 GB (占总显存 6.25%)
```

### 6.2 参数和梯度的详细分布

```
内存地址视图 (简化):

GPU 0 显存布局:
┌─────────────────────────────────────────────────┐
│ 地址范围            │ 内容        │ 大小        │
├─────────────────────────────────────────────────┤
│ 0x00000000         │ conv1.weight│ 37 KB       │
│ 0x00009600         │ conv1.bias  │ 256 B       │
│ ...                │             │             │
│ 0x00100000         │ layer1...   │ 863 KB      │
│ ...                │             │             │
│ 0x06580000         │ fc.weight   │ 8.2 MB      │
│ 0x06D80000         │ fc.bias     │ 4 KB        │
├─────────────────────────────────────────────────┤
│ 0x10000000         │ conv1.grad  │ 37 KB       │
│ 0x10009600         │ conv1.grad  │ 256 B       │
│ ...                │             │             │
│ 0x16580000         │ fc.grad     │ 8.2 MB      │
│ 0x16D80000         │ fc.grad     │ 4 KB        │
├─────────────────────────────────────────────────┤
│ 0x20000000         │ optimizer   │ 102 MB      │
│                    │ momentum    │             │
├─────────────────────────────────────────────────┤
│ 0x30000000         │ activations │ 490 MB      │
│                    │ (动态分配)  │             │
└─────────────────────────────────────────────────┘

关键观察:
1. 参数和梯度是分开存储的
2. 每个参数 w 有对应的梯度 w.grad
3. 优化器状态也为每个参数保存一份 momentum
4. 激活值在前向时分配，反向时释放
```

---

## 7. 完整代码示例

见下一个文件...