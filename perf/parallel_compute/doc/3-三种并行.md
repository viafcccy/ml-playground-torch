# 分布式训练深度剖析：完整代码和并行模式对比
## 第二部分：实践代码和进阶内容

---

## 7. 完整代码示例

### 7.1 带详细注释的训练代码

```python
"""
完整的 ResNet-50 4-GPU 分布式训练示例
每个关键步骤都有详细注释，说明每张卡在做什么
"""

import os
import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, DistributedSampler
import torchvision.models as models
import torchvision.transforms as transforms
import torchvision.datasets as datasets


def setup(rank, world_size):
    """
    初始化分布式环境
    
    参数:
        rank: 当前进程的全局 rank (0, 1, 2, 3)
        world_size: 总进程数 (4)
    """
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12355'
    
    # 配置 NCCL (只在必要时)
    os.environ['NCCL_IB_DISABLE'] = '1'      # 单机无 InfiniBand
    os.environ['NCCL_DEBUG'] = 'WARN'         # 减少日志
    
    # 初始化进程组
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
    
    print(f"[Rank {rank}] 初始化完成")


def cleanup():
    """清理分布式环境"""
    dist.destroy_process_group()


def prepare_dataloader(rank, world_size, batch_size=128):
    """
    准备数据加载器
    
    关键: 使用 DistributedSampler 确保每个 GPU 拿到不同数据
    
    返回:
        dataloader: 数据加载器
        sampler: 分布式采样器 (需要每个 epoch 设置 seed)
    """
    # 数据预处理
    transform = transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # 加载 ImageNet 数据集 (这里用 CIFAR10 演示)
    dataset = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=transform
    )
    
    # 分布式采样器
    # 作用: 将数据集分成 world_size 份，每个 rank 拿一份
    sampler = DistributedSampler(
        dataset,
        num_replicas=world_size,  # 总 GPU 数
        rank=rank,                # 当前 GPU 编号
        shuffle=True,             # 打乱数据
        seed=42                   # 随机种子
    )
    
    # 数据加载器
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size // world_size,  # 每个 GPU 的 batch size
        sampler=sampler,          # 使用分布式采样器
        num_workers=4,            # 数据加载线程数
        pin_memory=True,          # 加速 CPU→GPU 传输
    )
    
    if rank == 0:
        print(f"数据加载器准备完成:")
        print(f"  - 总 batch size: {batch_size}")
        print(f"  - 每 GPU batch size: {batch_size // world_size}")
        print(f"  - 数据集大小: {len(dataset)}")
        print(f"  - 每 GPU 样本数: {len(dataset) // world_size}")
    
    return dataloader, sampler


def create_model(rank):
    """
    创建模型
    
    步骤:
    1. 在 CPU 上创建模型
    2. 移动到对应的 GPU
    3. 用 DDP 包装
    
    返回:
        model: DDP 包装后的模型
    """
    # 1. 创建 ResNet-50
    model = models.resnet50(pretrained=False, num_classes=10)  # CIFAR10 用 10 类
    
    if rank == 0:
        print(f"模型创建完成:")
        param_count = sum(p.numel() for p in model.parameters())
        print(f"  - 参数量: {param_count:,} ({param_count * 4 / 1024**2:.1f} MB in FP32)")
    
    # 2. 移动到对应 GPU
    model = model.cuda(rank)
    
    # 3. DDP 包装
    # 这是关键！DDP 会:
    #   - 在所有 GPU 上广播初始参数 (确保起点相同)
    #   - 在 backward() 时自动调用 NCCL All-Reduce 同步梯度
    model = DDP(
        model,
        device_ids=[rank],
        output_device=rank,
        
        # 梯度桶大小 (默认 25MB)
        # 梯度累积到 25MB 就触发 All-Reduce
        bucket_cap_mb=25,
        
        # 梯度作为桶视图 (节省显存)
        gradient_as_bucket_view=True,
        
        # 如果模型结构固定，设为 True 加速
        static_graph=False,
    )
    
    if rank == 0:
        print(f"DDP 包装完成")
    
    return model


def train_one_epoch(model, dataloader, criterion, optimizer, epoch, rank, world_size):
    """
    训练一个 epoch
    
    这个函数展示了每个 step 中每张卡的详细工作
    """
    model.train()
    
    # 用于统计
    total_loss = 0.0
    total_correct = 0
    total_samples = 0
    
    for step, (images, labels) in enumerate(dataloader):
        # ========== Phase 1: 数据传输 ==========
        # 每个 GPU 将自己的 mini-batch 从 CPU 传到 GPU
        images = images.cuda(rank, non_blocking=True)
        labels = labels.cuda(rank, non_blocking=True)
        
        # 此时:
        # GPU 0: images[0:32], labels[0:32]
        # GPU 1: images[32:64], labels[32:64]
        # GPU 2: images[64:96], labels[64:96]
        # GPU 3: images[96:128], labels[96:128]
        
        # ========== Phase 2: 前向传播 ==========
        # 各 GPU 独立计算，无通信
        outputs = model(images)
        
        # 此时:
        # GPU 0: outputs_0 (通过 GPU 0 的 32 张图计算)
        # GPU 1: outputs_1 (通过 GPU 1 的 32 张图计算)
        # GPU 2: outputs_2 (通过 GPU 2 的 32 张图计算)
        # GPU 3: outputs_3 (通过 GPU 3 的 32 张图计算)
        
        # ========== Phase 3: 计算损失 ==========
        # 各 GPU 独立计算自己的损失
        loss = criterion(outputs, labels)
        
        # 此时:
        # GPU 0: loss_0 (只基于 GPU 0 的数据)
        # GPU 1: loss_1 (只基于 GPU 1 的数据)
        # GPU 2: loss_2 (只基于 GPU 2 的数据)
        # GPU 3: loss_3 (只基于 GPU 3 的数据)
        # 四个损失值很可能不同！
        
        # ========== Phase 4: 反向传播 + 梯度同步 ==========
        optimizer.zero_grad()
        
        # 关键！DDP 在这里自动处理梯度同步
        loss.backward()
        
        # backward() 做了什么？
        # 1. 计算本地梯度 (各 GPU 独立)
        #    GPU 0: grad_0 (基于 loss_0 反向传播)
        #    GPU 1: grad_1 (基于 loss_1 反向传播)
        #    GPU 2: grad_2 (基于 loss_2 反向传播)
        #    GPU 3: grad_3 (基于 loss_3 反向传播)
        #
        # 2. 每层梯度就绪后立即 All-Reduce (后台异步)
        #    grad_avg = (grad_0 + grad_1 + grad_2 + grad_3) / 4
        #
        # 3. 所有梯度同步完成后，backward() 返回
        #    此时所有 GPU 的梯度完全相同: grad_avg
        
        # ========== Phase 5: 参数更新 ==========
        # 各 GPU 独立更新参数
        optimizer.step()
        
        # 因为梯度相同，所以更新后参数也相同！
        # param_new = param_old - lr * grad_avg
        # 所有 GPU 的 param_new 完全一致
        
        # ========== 统计 (需要跨 GPU 汇总) ==========
        # 计算准确率
        _, predicted = outputs.max(1)
        correct = (predicted == labels).sum().item()
        
        # 这些是本地统计，需要跨 GPU 求和
        total_loss += loss.item()
        total_correct += correct
        total_samples += labels.size(0)
        
        # 打印进度 (只在 rank 0 打印)
        if rank == 0 and step % 10 == 0:
            print(f"Epoch {epoch}, Step {step}/{len(dataloader)}, "
                  f"Loss: {loss.item():.4f}")
    
    # ========== 跨 GPU 汇总指标 ==========
    # 将所有 GPU 的统计数据汇总
    
    # 方法 1: 手动 All-Reduce
    loss_tensor = torch.tensor([total_loss]).cuda(rank)
    correct_tensor = torch.tensor([total_correct]).cuda(rank)
    samples_tensor = torch.tensor([total_samples]).cuda(rank)
    
    dist.all_reduce(loss_tensor, op=dist.ReduceOp.SUM)
    dist.all_reduce(correct_tensor, op=dist.ReduceOp.SUM)
    dist.all_reduce(samples_tensor, op=dist.ReduceOp.SUM)
    
    global_loss = loss_tensor.item() / len(dataloader) / world_size
    global_accuracy = correct_tensor.item() / samples_tensor.item()
    
    if rank == 0:
        print(f"\nEpoch {epoch} 完成:")
        print(f"  - 平均损失: {global_loss:.4f}")
        print(f"  - 准确率: {global_accuracy * 100:.2f}%")
    
    return global_loss, global_accuracy


def main():
    """主函数"""
    # ========== 配置 ==========
    world_size = 4  # 4 个 GPU
    epochs = 10
    batch_size = 128  # 全局 batch size
    learning_rate = 0.1
    
    # ========== 初始化 ==========
    # 每个 GPU 启动一个进程
    import torch.multiprocessing as mp
    
    def worker(rank, world_size):
        """每个 GPU 运行的工作函数"""
        print(f"\n{'='*60}")
        print(f"GPU {rank} 启动")
        print(f"{'='*60}\n")
        
        # 1. 初始化分布式环境
        setup(rank, world_size)
        
        # 2. 设置当前 GPU
        torch.cuda.set_device(rank)
        
        # 3. 准备数据
        dataloader, sampler = prepare_dataloader(rank, world_size, batch_size)
        
        # 4. 创建模型
        model = create_model(rank)
        
        # 5. 损失函数和优化器
        criterion = nn.CrossEntropyLoss().cuda(rank)
        optimizer = torch.optim.SGD(
            model.parameters(),
            lr=learning_rate,
            momentum=0.9,
            weight_decay=1e-4
        )
        
        # 6. 训练循环
        for epoch in range(epochs):
            # 设置 epoch (用于 shuffle)
            sampler.set_epoch(epoch)
            
            # 训练一个 epoch
            train_one_epoch(
                model, dataloader, criterion, optimizer,
                epoch, rank, world_size
            )
        
        # 7. 清理
        cleanup()
        
        if rank == 0:
            print(f"\n{'='*60}")
            print(f"训练完成！")
            print(f"{'='*60}\n")
    
    # 启动多进程
    mp.spawn(worker, args=(world_size,), nprocs=world_size, join=True)


if __name__ == "__main__":
    main()
```

### 7.2 运行和输出示例

```bash
$ python distributed_resnet50.py

==============================================================
GPU 0 启动
==============================================================

==============================================================
GPU 1 启动
==============================================================

==============================================================
GPU 2 启动
==============================================================

==============================================================
GPU 3 启动
==============================================================

[Rank 0] 初始化完成
[Rank 1] 初始化完成
[Rank 2] 初始化完成
[Rank 3] 初始化完成

数据加载器准备完成:
  - 总 batch size: 128
  - 每 GPU batch size: 32
  - 数据集大小: 50000
  - 每 GPU 样本数: 12500

模型创建完成:
  - 参数量: 25,557,032 (97.5 MB in FP32)

DDP 包装完成

Epoch 0, Step 0/390, Loss: 2.3045
Epoch 0, Step 10/390, Loss: 2.2891
Epoch 0, Step 20/390, Loss: 2.1234
...

Epoch 0 完成:
  - 平均损失: 1.8234
  - 准确率: 45.23%

...

==============================================================
训练完成！
==============================================================
```

---

## 8. 其他并行模式对比

### 8.1 模式对比总览

```
┌────────────────────────────────────────────────────────────┐
│              三种主要并行模式                               │
├────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 数据并行 (Data Parallelism)                            │
│     - 每个 GPU: 完整模型 + 部分数据                        │
│     - 同步: 梯度 All-Reduce                                │
│     - 适用: 模型能放入单卡                                 │
│                                                             │
│  2. 模型并行 (Model Parallelism)                           │
│     - 每个 GPU: 部分模型 + 完整数据                        │
│     - 同步: 激活值传递                                     │
│     - 适用: 模型太大放不下单卡                             │
│                                                             │
│  3. 流水线并行 (Pipeline Parallelism)                      │
│     - 每个 GPU: 部分模型 + 部分数据                        │
│     - 同步: micro-batch 流水                               │
│     - 适用: 大模型 + 高效利用                              │
│                                                             │
└────────────────────────────────────────────────────────────┘
```

### 8.2 数据并行详解 (前面已讲)

```
数据并行 (DDP):
┌─────────────────────────────────────────────────────────┐
│                                                          │
│  GPU 0           GPU 1           GPU 2           GPU 3  │
│  ┌────────┐     ┌────────┐     ┌────────┐     ┌────────┐│
│  │ 完整   │     │ 完整   │     │ 完整   │     │ 完整   ││
│  │ ResNet │     │ ResNet │     │ ResNet │     │ ResNet ││
│  │ 102MB  │     │ 102MB  │     │ 102MB  │     │ 102MB  ││
│  └───┬────┘     └───┬────┘     └───┬────┘     └───┬────┘│
│      │              │              │              │     │
│      ▼              ▼              ▼              ▼     │
│  ┌────────┐     ┌────────┐     ┌────────┐     ┌────────┐│
│  │Data 0-31│    │Data32-63│    │Data64-95│    │Data96..││
│  └────────┘     └────────┘     └────────┘     └────────┘│
│                                                          │
│  前向: 各自独立计算                                      │
│  反向: All-Reduce 梯度 ──────────────┐                  │
│        ↓          ↓          ↓          ↓              │
│     grad_avg   grad_avg   grad_avg   grad_avg          │
│                                                          │
│  优点: 实现简单，扩展性好                                │
│  缺点: 模型必须放入单卡                                  │
└─────────────────────────────────────────────────────────┘
```

### 8.3 模型并行详解

```
模型并行 (Tensor Parallelism):
┌─────────────────────────────────────────────────────────┐
│ 假设: 将 ResNet-50 的每一层切分到不同 GPU                │
│                                                          │
│  GPU 0           GPU 1           GPU 2           GPU 3  │
│  ┌────────┐     ┌────────┐     ┌────────┐     ┌────────┐│
│  │ conv1  │ ──> │ layer1 │ ──> │ layer2 │ ──> │ layer3 ││
│  │ 37KB   │     │ 863KB  │     │ 4.9MB  │     │ 28.4MB ││
│  └───┬────┘     └───┬────┘     └───┬────┘     └───┬────┘│
│      │              │              │              │     │
│      └──────────────┴──────────────┴──────────────┘     │
│                     完整数据流                            │
│      ┌──────────────────────────────────────────┐       │
│      │ Input [32, 3, 224, 224]                  │       │
│      └──────────────────────────────────────────┘       │
│                                                          │
│  前向: 数据依次通过各 GPU                                │
│        GPU 0 计算完 → 传给 GPU 1 → GPU 1 计算 → ...     │
│                                                          │
│  反向: 梯度反向传播                                      │
│        GPU 3 ← GPU 2 ← GPU 1 ← GPU 0                   │
│                                                          │
│  优点: 可以训练超大模型                                  │
│  缺点: GPU 利用率低 (串行)，通信多                       │
└─────────────────────────────────────────────────────────┘

实际例子: GPT-3 (175B 参数)
┌─────────────────────────────────────────────────────────┐
│ 模型太大，单卡放不下 (175B × 4 bytes = 700 GB!)         │
│                                                          │
│ 解决: 将每层的权重矩阵切分                               │
│                                                          │
│ Transformer 层:                                          │
│   QKV 投影: [12288, 12288] = 144M 参数 = 576 MB        │
│                                                          │
│ 切分到 4 个 GPU:                                         │
│   GPU 0: [12288, 3072]  = 144 MB                        │
│   GPU 1: [12288, 3072]  = 144 MB                        │
│   GPU 2: [12288, 3072]  = 144 MB                        │
│   GPU 3: [12288, 3072]  = 144 MB                        │
│                                                          │
│ 前向计算:                                                │
│   Input [B, 12288]                                      │
│   ├─> GPU 0: Q0 = Input @ W_Q0  (并行)                 │
│   ├─> GPU 1: Q1 = Input @ W_Q1  (并行)                 │
│   ├─> GPU 2: Q2 = Input @ W_Q2  (并行)                 │
│   └─> GPU 3: Q3 = Input @ W_Q3  (并行)                 │
│                                                          │
│   All-Gather: Q = [Q0, Q1, Q2, Q3]                      │
│                                                          │
└─────────────────────────────────────────────────────────┘
```

### 8.4 流水线并行详解

```
流水线并行 (Pipeline Parallelism):
┌─────────────────────────────────────────────────────────┐
│ 思想: 将模型分层 + 数据分批，形成流水线                  │
│                                                          │
│ 模型分层:                                                │
│   GPU 0: Layer 0-5                                      │
│   GPU 1: Layer 6-11                                     │
│   GPU 2: Layer 12-17                                    │
│   GPU 3: Layer 18-23                                    │
│                                                          │
│ 数据分批 (Micro-batches):                               │
│   Batch 128 分成 4 个 micro-batch, 每个 32              │
│                                                          │
│ 时间线:                                                  │
│ Time  GPU 0       GPU 1       GPU 2       GPU 3         │
│ ────────────────────────────────────────────────────────│
│  0    [MB1-Fwd]                                         │
│  1    [MB2-Fwd]  [MB1-Fwd]                              │
│  2    [MB3-Fwd]  [MB2-Fwd]  [MB1-Fwd]                   │
│  3    [MB4-Fwd]  [MB3-Fwd]  [MB2-Fwd]  [MB1-Fwd]        │
│  4    [MB1-Bwd]  [MB4-Fwd]  [MB3-Fwd]  [MB2-Fwd]        │
│  5    [MB2-Bwd]  [MB1-Bwd]  [MB4-Fwd]  [MB3-Fwd]        │
│  6    [MB3-Bwd]  [MB2-Bwd]  [MB1-Bwd]  [MB4-Fwd]        │
│  7    [MB4-Bwd]  [MB3-Bwd]  [MB2-Bwd]  [MB1-Bwd]        │
│  8               [MB4-Bwd]  [MB3-Bwd]  [MB2-Bwd]        │
│  9                          [MB4-Bwd]  [MB3-Bwd]        │
│ 10                                     [MB4-Bwd]        │
│                                                          │
│ Fwd = 前向传播, Bwd = 反向传播, MB = Micro-batch        │
│                                                          │
│ 优点: GPU 利用率高，支持大模型                           │
│ 缺点: 实现复杂，有流水线气泡 (bubble)                    │
└─────────────────────────────────────────────────────────┘

实际应用: GPipe (Google)
┌─────────────────────────────────────────────────────────┐
│ AmoebaNet (557M 参数) 在 8 个 GPU 上训练:               │
│                                                          │
│ 配置:                                                    │
│   - 模型分为 8 部分 (每 GPU 一部分)                     │
│   - Batch 512 分为 8 个 micro-batch (每个 64)           │
│   - 流水线深度: 8                                        │
│                                                          │
│ 性能:                                                    │
│   - GPU 利用率: 82% (vs 串行的 12.5%)                   │
│   - 训练速度: 接近线性加速                               │
│   - 通信量: 比数据并行少 (只传激活值)                    │
└─────────────────────────────────────────────────────────┘
```

### 8.5 混合并行 (最先进)

```
3D 并行 = 数据并行 + 模型并行 + 流水线并行

用于超大模型 (如 GPT-3, Megatron):
┌─────────────────────────────────────────────────────────┐
│                      3D 并行架构                         │
│                                                          │
│ 假设: 64 个 GPU, GPT-3 (175B 参数)                      │
│                                                          │
│ 维度 1: 数据并行 (DP) - 4 份                            │
│   ├─ Replica 0: 16 GPU                                  │
│   ├─ Replica 1: 16 GPU                                  │
│   ├─ Replica 2: 16 GPU                                  │
│   └─ Replica 3: 16 GPU                                  │
│                                                          │
│ 维度 2: 流水线并行 (PP) - 4 阶段                        │
│   每个 Replica 内:                                       │
│   ├─ Stage 0: Layers 0-23    (4 GPU)                   │
│   ├─ Stage 1: Layers 24-47   (4 GPU)                   │
│   ├─ Stage 2: Layers 48-71   (4 GPU)                   │
│   └─ Stage 3: Layers 72-95   (4 GPU)                   │
│                                                          │
│ 维度 3: 模型并行 (TP) - 4 路                            │
│   每个 Stage 内，权重按列切分:                           │
│   ├─ GPU 0: 列 0-3071                                   │
│   ├─ GPU 1: 列 3072-6143                                │
│   ├─ GPU 2: 列 6144-9215                                │
│   └─ GPU 3: 列 9216-12287                               │
│                                                          │
│ 总览:                                                    │
│   4 (DP) × 4 (PP) × 4 (TP) = 64 GPU                    │
│                                                          │
│ 通信模式:                                                │
│   - TP: 频繁 (每层内 All-Reduce)                        │
│   - PP: 中等 (Stage 间传激活值)                         │
│   - DP: 少 (只在反向传播后 All-Reduce 梯度)             │
└─────────────────────────────────────────────────────────┘

网络要求:
┌─────────────────────────────────────────────────────────┐
│ TP (Tensor Parallel):                                   │
│   - 需要低延迟 (<5 μs)                                  │
│   - 需要高带宽 (>100 GB/s)                              │
│   - 建议: NVLink (节点内)                               │
│                                                          │
│ PP (Pipeline Parallel):                                 │
│   - 中等延迟可接受 (~10 μs)                             │
│   - 中等带宽 (~25 GB/s)                                 │
│   - 建议: InfiniBand                                    │
│                                                          │
│ DP (Data Parallel):                                     │
│   - 延迟不敏感 (~100 μs)                                │
│   - 带宽需求看模型大小                                   │
│   - 可用: 以太网 / InfiniBand                           │
└─────────────────────────────────────────────────────────┘
```

---

## 9. 性能分析

### 9.1 通信时间分解

```
单次迭代时间分解 (ResNet-50, 4 GPU, PCIe):

┌─────────────────────────────────────────────────────────┐
│ 操作                  │ 时间 (ms) │ 占比    │ GPU 利用率 │
├─────────────────────────────────────────────────────────┤
│ 数据加载 (CPU→GPU)    │    5      │  10%    │   0%      │
│ 前向传播              │   15      │  30%    │  95%      │
│ 计算损失              │    1      │   2%    │  90%      │
│ 反向传播 (计算)       │   20      │  40%    │  95%      │
│ 梯度同步 (NCCL)       │    3      │   6%    │  10%      │
│ 参数更新              │    5      │  10%    │  80%      │
│ 其他                  │    1      │   2%    │   -       │
├─────────────────────────────────────────────────────────┤
│ 总计                  │   50      │ 100%    │  平均 75% │
└─────────────────────────────────────────────────────────┘

关键观察:
1. 梯度同步只占 6% (因为与反向传播重叠)
2. GPU 利用率 75% 是合理的
3. 主要瓶颈是计算 (前向 + 反向)
```

### 9.2 扩展性分析

```
理论加速比 vs 实际加速比:

GPU 数量    理论加速    实际加速    效率
────────────────────────────────────────
   1          1x          1x       100%
   2          2x        1.9x        95%
   4          4x        3.7x        92%
   8          8x        7.2x        90%
  16         16x       13.8x        86%
  32         32x       26.5x        83%

效率下降原因:
1. 通信开销增加
2. 负载不均衡
3. 同步等待时间
4. 系统瓶颈 (网络、存储)
```

### 9.3 内存效率

```
显存占用对比 (ResNet-50):

模式              每 GPU 显存      总显存利用
──────────────────────────────────────────────
单 GPU             2.5 GB          2.5 GB
数据并行 (4 GPU)   1.0 GB          4.0 GB
模型并行 (4 GPU)   0.7 GB          2.8 GB
流水线并行 (4 GPU) 0.8 GB          3.2 GB

观察:
- 数据并行总显存利用最高 (每卡有完整副本)
- 模型并行单卡显存最低 (权重分片)
- 流水线并行介于两者之间
```

---

## 10. 总结

### 关键要点

**数据并行 (DDP)**:
- ✅ 参数: 每个 GPU 完整拷贝
- ✅ 数据: 分片 (不同 GPU 不同数据)
- ✅ 同步: 梯度 All-Reduce
- ✅ 通信: 反向传播时 (与计算重叠)
- ✅ 适用: 模型能放入单卡 (<16GB)

**你的 4x T4 环境**:
- 每卡 16GB 显存
- PCIe Gen3 互连 (16 GB/s)
- 适合数据并行
- ResNet-50 级别模型完全没问题
- 通信不是瓶颈 (只占 6%)

### 下一步学习

1. **实践**: 运行上面的完整代码
2. **Profile**: 用 `nsys` 查看时间线
3. **优化**: 调整 batch size, gradient accumulation
4. **进阶**: 尝试混合精度训练 (FP16)
5. **扩展**: 研究更大模型的并行策略

完整文档已准备好！🚀